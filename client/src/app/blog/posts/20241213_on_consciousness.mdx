---
title: "Consciousness an Illusion?"
blurb: "System watch me"
coverImage: 208
author: "Dereck Mezquita"
date: 2024-12-13
tags: [science, neuroscience, consciousness, brain, psychology]
published: false
comments: true
---

For thousands of years philosophers have pondered the nature of what we call consciousness. More recently have scientist began to probe this phenomenon. Some claim it to be a mysterious force that inhabits a physical body, while others treat it as an emergent property of complex information systems. Yet none truly provides a definite answer as to how it arises or more importantly what it even is. In this exploration, I propose a radical hypothesis: **consciousness is an illusion**.

The question we should seek should not be what is consciousness. Rather, how does this illusion arise?

## What is consciousness?

Before we consider my claim, let us first survey what many have said about the subject: what even is consciousness? Several theories dominate the landscape:

### 1. Physicalist theories

- **Materialism**: argues that this phenomenon arises solely from physical processes in the brain. Modern neuroscience supports this view, consistently correlating neural activity with subjective reports of experience.
- **Neurobiological theories**: aim to pinpoint specific brain structures and processes that give rise to states we call "conscious." For example, neural correlates of consciousness (NCC) are studied to identify which patterns of brain activity align with certain experiences.
- **Quantum Theories**: suggest that quantum phenomena within neurons might generate the experience. Although intriguing, these ideas lack broad acceptance and clear empirical support.

### 2. Fundamental property theories

- **Dualism**: famously championed by René Descartes, it posits a strict division between the non-physical mind and the physical body. Under this view, the mind or soul is separate and non-material.
- **Panpsychism**: proposes that what we call subjective experience is a fundamental feature of reality. Even the smallest particles possess some unit of it, making it ubiquitous.

### 3. Emergent/integrative theories

- **Global Workspace Theory**: likens the experience to a spotlight that illuminates particular mental processes, making them accessible to other cognitive functions. It emerges from the dynamic integration of neural systems.
- **Integrated Information Theory (IIT)**: claims that what we label as conscious experience corresponds to a system's capacity to integrate information. The richer and more interconnected the information flow, the closer the system approximates what we deem as "conscious."
- **Emergentism**: suggests that properties like subjective experience arise from complex interactions of simpler components. Novel qualities emerge from complexity that are not evident in the individual parts.

From the aforementioned theories I am a fan more of the physicalist/emergent and integrative theories; we will call these the materialist theories from now on. The fundamentalist theories discredit any scientific probing. 

These materialist theories seek to correlate consciousness (mental states) with physical or information processing. Yet they seldom explain what the essence of this subjective experience truly is. They give us frameworks to address correlates or conditions, but the intrinsic nature of the phenomenon remains elusive.

Questions remain:

<Alert type='important'>
1. What are we studying if we cannot define it precisely?
2. How do we explore or communicate something internal, private, and entirely subjective?
3. Are those around us truly having an inner perspective similar to ours, and if so, how do we know?
</Alert>

This is the hard problem of what we call consciousness: the persistent gap between objective measurement and subjective experience. Science can detail mechanisms and conditions under which certain states seem to arise, but it will never fully explain what these states are from a subjective standpoint. By its very nature, the supposed phenomenon is subjective and resists external verification. The best scientific definition we have is:

<blockquote>
Consciousness is the state or quality of being aware of external objects or something within oneself.
</blockquote>

Yet even this definition is problematic. Consider the key terms:

- **State**: how do we qualify a "state" within a being whose internal processes we cannot directly observe? We can infer states from external behavior or brain activity, but these are indirect indicators.
- **Aware**: awareness is subjective. How can we confirm that another entity is truly "aware" rather than merely responding to stimuli? If you push one end of a stick, the other end moves, but we would not say that one end is aware of the other.
- **Oneself**: the notion of a self is notoriously difficult to pin down. What if an entity's internal perspective differs so radically from ours that "self" is not even a coherent concept in its internal framework?

These problems become evident when considering animals, infants, artificial systems, or even hypothetical aliens. How can we know they have any internal perspective at all that resembles our own?

At best, this definition points to a phenomenon we suspect exists, but we cannot be certain how it manifests internally. We have no direct window into another being's mind, and no way to confirm that the terms we use, _state, aware, oneself_ actually map onto a consistent internal reality. In other words, what we call consciousness remains a black box, an internally inaccessible construct that may forever elude complete understanding.

In practice, since we cannot observe the "within," science often defaults to describing these states in terms of outward signs: inputs, outputs, and behaviors that we, as external observers, deem logical or meaningful. Yet this approach risks treating the label as something neatly defined, when in fact we cannot even be sure what we are labeling.

## Consciousness as an illusion (or an unfathomable construct)

Here is the central issue: perhaps what we call consciousness is simply the emergent result of complex information processing. I do not deny that possibility. It could be that billions of neurons interacting, integrating sensory data, memories, emotions, and thoughts produce what feels to us like a unified experience, something to which we instinctively want to attribute a name. If so, then what we label as consciousness might not be a magical spark, but a natural product of complexity as the materialist theories suggest.

However, a fundamental problem remains: we have no concrete definition of what this "awareness" actually is. We have no clear benchmark against which to measure it, nor a vantage point outside our own heads from which to observe it.

To put my problem into simple words:

> Even if a brilliant scientist were to have discover the essence of consciousness how would he then communicate this to others? How would he know that others are experiencing the same thing?

Our only reference is our own subjective experience, which is partial and biased. We are prisoners of our minds.

Moreover, we are prisoners to our present experience - we are prisoners to our focus. We only ever perceive one slice of our supposed inner experience at any given time, one cannot pay attention to everything at once. I hypothesise some drugs might alter this focus and allow access to more of this inner experience "consciousness", but that is a topic for another time.

As such this internal view is incomplete and personal. We cannot step outside our own minds for a better look, nor can we peer into another mind to confirm that it aligns with our assumptions.

Because our understanding is locked within this subjective frame, it is pointless to argue about what the experience "truly" is. We might call it an emergent feature of information processing, but that only restates what brains do without capturing any true essence. The concept remains a moving target: a label pointing to a phenomenon we cannot fully define or measure. Without a reliable external reference, any definition mirrors our own limited perspective rather than offering a clear articulation of an identifiable entity.

This predicament leads us to call what we refer to as consciousness an illusion. Not an illusion in the sense that nothing happens, but in the sense that we treat it as if it were a well-defined, magical entity when it may simply be a convenient fiction. What if all we have is the brain's narrative about itself, a story that convinces us we are something singular and essential, when in reality there is only complexity interpreting itself?

It might be best to leave the question of this so called consciousness to philosophers. The brain processes information in intricate ways; we can study these mechanisms, but we should not mislead ourselves by treating the notion of consciousness as a tangible object. Our resistance to this conclusion stems from how dear our sense of self is to us. We have evolved to value the feeling of being distinct individuals. Yet when we try to define what we mean by these internal experiences, we find ourselves mired in subjectivity and doubt.

## A Proposed Emergent Mechanism: Subnetworks Observing Themselves

If we accept that the notion of consciousness is an illusion or a construct, we can still explore how this illusion might arise. This is the question we should address rather than what is consciousness a pure epistemological question we should ask:

1. How does the brain process information?
1. What 

Consider the brain or any sufficiently complex processing system—as a vast network of interconnected nodes, each performing specialized tasks. As this network grows in complexity, it naturally breaks into subnetworks that are more tightly connected internally than to the rest of the system.

Imagine a huge graph of interconnected components, where some clusters form relatively distinct modules. These subnetworks handle different tasks: vision, memory, language, emotional responses, and so forth. Now consider that one or more of these subnetworks gains the ability to observe or monitor the activity of others. In the human brain, for instance, the prefrontal cortex might be one such system, integrating and evaluating signals from areas responsible for perception, memory, or emotional tone.

By having a subsystem observe and interpret the activity of others, the whole network can generate a meta-level representation—a kind of internal commentary about its own processes. This self-referential monitoring might create the impression of a central observer, giving rise to that ineffable feeling we loosely label as consciousness. In other words, what we experience as awareness could be the brain's attempt to model its own internal states, weaving together disparate threads of information into a coherent narrative.

- **Compartmentalization**: As networks grow, they form specialized clusters that process different types of information independently.  
- **Internal Observation**: Some subnetworks integrate information about the states of other parts of the system.  
- **Emergent Self-Representation**: By observing and interpreting these signals, the system crafts a model of "self" that perceives and interprets experiences.  
- **The Illusion of a Unified Observer**: This self-model is not distinct from the processes it observes, but an emergent pattern. The feeling of being an "experiencer" arises when the system's narrative about itself appears seamless and continuous.

In this view, the so-called magical spark of consciousness is replaced with recursive interplay: networks that have become complex enough to reflect upon their own activity. There is no hidden essence, only intricate feedback loops that generate a convincing illusion of an integrated, experiencing self.

## Consciousness as Mirage: The Hard Limits of Science

Attempts to measure this inner dimension rely on:

1. **Neuroscientific Methods (fMRI, EEG)**: Correlate brain activity with reported states, but do not directly measure any supposed inner phenomenon.  
2. **Behavioral Tests (Responsiveness Scales)**: Gauge reactions to stimuli, not the internal "feel" of being aware.  
3. **Phenomenological Reporting**: Subjective self-reports that cannot be independently verified.  
4. **Information Integration Metrics**: Highlight complexity in processing, correlating with higher-order states but never capturing an essence.

All these approaches measure correlates, never the supposed phenomenon itself. The subjective, first-person quality remains inaccessible. Without a solid definition, we measure shadows rather than the object supposedly casting them.

## A Disturbing Possibility: Varying Internal Worlds

We use the Turing test to decide if a machine can mimic human-like responses convincingly enough to appear as if it possesses an inner experience. Yet we grant other humans the assumption of having a rich internal perspective without any similar test. If the phenomenon we call consciousness is really just an emergent narrative arising from complex information processing, what then stops us from applying the same skeptical scrutiny to other humans?

This leads to a dark and unsettling thought. If all we rely on are outward indicators—speech, emotional expressions, and social behavior—we cannot confirm that others have the same intricate self-referential structures that we assume for ourselves. Philosophers have imagined "philosophical zombies," entities indistinguishable from fully sentient beings but lacking any genuine internal narrative. How do we know that some people around us are not simply enacting roles, mimicking patterns of self-reflection without actually experiencing them?

We already acknowledge that individuals differ in countless measurable ways: height, memory, intelligence, and so forth. We accept that a child does not integrate information as fully as an adult. It is not a stretch to consider that the capacity for self-referential modeling might vary just as widely. If this capacity emerges gradually and depends on countless subtle factors, then the richness of one's internal perspective could differ dramatically from one individual to another.

Some might possess only a rudimentary internal narrative, their level of self-observation sparse or limited. Others might have a more elaborate inner framework that allows deep reflection and complex subjective experience. More unsettling still is the possibility that some beings might be nothing more than finely tuned automatons, simulating patterns of self-reflection without truly possessing them.

We cannot verify these possibilities. Yet the notion alone undermines our comforting assumption that everyone shares a similar kind of inner life. It forces us to confront the idea that what we take for granted—our presumed uniformity of internal experiences—may be far from universal. If what we cherish as self-awareness can vary, or may not exist in some, then the empathetic foundations of our social world become uncertain.

Does it matter if we never detect a difference? Perhaps not. We might continue as though everyone we encounter shares our inner complexity. Yet the knowledge that this assumption could be an illusion casts a long shadow. Our moral and social constructs, built on a presumed similarity of inner experience, may rest on shaky ground. If the world includes beings with drastically different, or even absent, internal narratives, then our notions of understanding, empathy, and community may need profound reconsideration.

## Conclusion: Embracing the Epistemological Limit

Our subjective awareness feels real and important. Illusion or not, we do experience something. But the central challenge remains: we cannot step outside our own minds to examine this phenomenon objectively, nor can we confirm its nature in others. Without a stable reference point, the very concept dissolves into ambiguity.

This perspective frees us from the endless, fruitless search for a thing we cannot define. Instead of chasing an elusive essence, we might focus on how brains produce the appearance of an inner life, and how that appearance shapes behavior, societies, and moral frameworks. Even if the notion of consciousness is not a discrete, special substance, it remains influential. It guides our decisions, informs our sense of identity, and imbues our fleeting moments with meaning.

Recognizing that what we call consciousness may be an ill-defined emergent property—an indispensable but mysterious facet of complex information processing—does not diminish human experience. Instead, it encourages a deeper understanding of the processes underlying our perceptions, while acknowledging that some questions may remain out of reach. Ultimately, we gain humility and a new lens: seeing what we call consciousness not as a phenomenon awaiting discovery, but as an ever-elusive construct shaped by the very minds seeking to comprehend it.