---
title: "Statistics with R II: Intermediate"
chapter: "Chapter 4: Logistic Regression"
part: "Part 3: Extensions and Applications"
coverImage: 13
author: "Dereck Mezquita"
date: "2026-01-19"
tags: [statistics, mathematics, logistic-regression, multinomial, ordinal, R, biomedical]
published: true
comments: true
output:
  html_document:
    keep_md: true
---



# Part 3: Extensions and Applications

Standard logistic regression handles binary outcomes. But what if you have three or more categories? This part extends logistic regression to **multinomial** outcomes (unordered categories) and **ordinal** outcomes (ordered categories), and covers practical issues like variable selection and regularisation.


``` r
box::use(
    data.table[...],
    ggplot2
)

# Load nnet for multinomial regression
library(nnet)
library(MASS)  # For ordinal regression
```


``` r
# Load datasets
nhanes <- fread("../../../data/primary/nhanes.csv")
breast_cancer <- fread("../../../data/bioinformatics/breast_cancer_wisconsin.csv")

cat("Datasets loaded.\n")
```

```
#> Datasets loaded.
```

---

## Table of Contents

## 4.11 Multinomial Logistic Regression

### 4.11.1 When Outcomes Have Multiple Categories

**Prose and Intuition**

Sometimes the outcome isn't binary — it has 3+ unordered categories:
- Diagnosis: Cancer subtype A, B, or C
- Treatment response: Complete, partial, or no response
- Health status: Healthy, pre-diabetic, or diabetic

**Multinomial logistic regression** extends binary logistic regression by modelling each category against a reference category.

**Mathematical Definition**

For $J$ categories, we model $J-1$ log-odds relative to a reference category (say, category 1):

$$\log\left(\frac{P(Y = j)}{P(Y = 1)}\right) = \boldsymbol{\beta}_j' \mathbf{X}, \quad j = 2, \ldots, J$$

This gives us $J-1$ sets of coefficients, one for each non-reference category.


``` r
# Create a 3-category outcome: Healthy, Pre-diabetic, Diabetic
# Based on HbA1c levels if available, or glucose levels
health_data <- nhanes[Age >= 18,
                      .(Age = Age, BMI = BMI, Gender = Gender,
                        Diabetes = Diabetes, DirectChol = DirectChol)]
health_data <- health_data[complete.cases(health_data)]

# Create health status categories
# Using Diabetes variable and creating intermediate category based on risk
health_data[, health_status := fifelse(
    Diabetes == "Yes", "Diabetic",
    fifelse(BMI > 30 | Age > 60, "At-Risk", "Healthy")
)]
health_data[, health_status := factor(health_status, levels = c("Healthy", "At-Risk", "Diabetic"))]

cat("Health Status Distribution:\n")
cat("===========================\n\n")
print(table(health_data$health_status))
cat("\nPercentages:\n")
print(round(prop.table(table(health_data$health_status)) * 100, 1))
```

```
#> Health Status Distribution:
#> ===========================
#> 
#> 
#>  Healthy  At-Risk Diabetic 
#>     3397     2947      674 
#> 
#> Percentages:
#> 
#>  Healthy  At-Risk Diabetic 
#>     48.4     42.0      9.6
```

### 4.11.2 Fitting Multinomial Logistic Regression


``` r
# Fit multinomial logistic regression
# Reference category is "Healthy"
model_multi <- multinom(health_status ~ Age + BMI + Gender,
                        data = health_data, trace = FALSE)

cat("Multinomial Logistic Regression:\n")
cat("================================\n\n")
cat("Reference category: Healthy\n\n")

# Summary
summary(model_multi)

# Calculate z-statistics and p-values
z <- summary(model_multi)$coefficients / summary(model_multi)$standard.errors
p <- 2 * (1 - pnorm(abs(z)))

cat("\nP-values:\n")
print(round(p, 4))
```

```
#> Multinomial Logistic Regression:
#> ================================
#> 
#> Reference category: Healthy
#> 
#> Call:
#> multinom(formula = health_status ~ Age + BMI + Gender, data = health_data, 
#>     trace = FALSE)
#> 
#> Coefficients:
#>          (Intercept)       Age       BMI Gendermale
#> At-Risk    -20.55743 0.1184699 0.5378167 -0.1845747
#> Diabetic   -25.54568 0.1550746 0.5767012  0.1825532
#> 
#> Std. Errors:
#>          (Intercept)         Age        BMI Gendermale
#> At-Risk    0.5315741 0.003578357 0.01451687 0.08178046
#> Diabetic   0.6212049 0.004554918 0.01575557 0.11191095
#> 
#> Residual Deviance: 7288.934 
#> AIC: 7304.934 
#> 
#> P-values:
#>          (Intercept) Age BMI Gendermale
#> At-Risk            0   0   0     0.0240
#> Diabetic           0   0   0     0.1028
```

### 4.11.3 Interpreting Multinomial Coefficients


``` r
# Extract odds ratios
cat("Odds Ratios (Relative to Healthy):\n")
cat("==================================\n\n")

coefs <- coef(model_multi)
or_multi <- exp(coefs)

# Format nicely
or_table <- data.table(
    Outcome = rep(rownames(or_multi), each = ncol(or_multi)),
    Variable = rep(colnames(or_multi), times = nrow(or_multi)),
    OR = as.vector(t(or_multi))
)

# Confidence intervals using profile likelihood would be ideal
# For simplicity, using Wald intervals
se <- summary(model_multi)$standard.errors
ci_lower <- exp(coefs - 1.96 * se)
ci_upper <- exp(coefs + 1.96 * se)

or_table[, CI_Lower := as.vector(t(ci_lower))]
or_table[, CI_Upper := as.vector(t(ci_upper))]

print(or_table[Variable != "(Intercept)",
               .(Outcome, Variable, OR = round(OR, 3),
                 CI = paste0("(", round(CI_Lower, 3), ", ", round(CI_Upper, 3), ")"))])

cat("\nInterpretation:\n")
cat("- For Age (At-Risk vs Healthy): OR =", round(or_multi["At-Risk", "Age"], 3), "\n")
cat("  Each year of age increases odds of being At-Risk (vs Healthy) by",
    round((or_multi["At-Risk", "Age"] - 1) * 100, 1), "%\n")
```

```
#> Odds Ratios (Relative to Healthy):
#> ==================================
#> 
#>     Outcome   Variable    OR             CI
#>      <char>     <char> <num>         <char>
#> 1:  At-Risk        Age 1.126 (1.118, 1.134)
#> 2:  At-Risk        BMI 1.712 (1.664, 1.762)
#> 3:  At-Risk Gendermale 0.831 (0.708, 0.976)
#> 4: Diabetic        Age 1.168 (1.157, 1.178)
#> 5: Diabetic        BMI 1.780 (1.726, 1.836)
#> 6: Diabetic Gendermale 1.200 (0.964, 1.495)
#> 
#> Interpretation:
#> - For Age (At-Risk vs Healthy): OR = 1.126 
#>   Each year of age increases odds of being At-Risk (vs Healthy) by 12.6 %
```

### 4.11.4 Predicted Probabilities


``` r
# Get predicted probabilities
health_data[, c("p_Healthy", "p_AtRisk", "p_Diabetic") :=
            as.data.table(predict(model_multi, type = "probs"))]

# Visualise how probabilities change with BMI at fixed age
bmi_seq <- data.table(
    BMI = rep(seq(18, 45, by = 0.5), 2),
    Age = 50,
    Gender = rep(c("female", "male"), each = 55)
)
pred_probs <- predict(model_multi, newdata = bmi_seq, type = "probs")
bmi_seq <- cbind(bmi_seq, as.data.table(pred_probs))

# Reshape for plotting
bmi_long <- melt(bmi_seq, id.vars = c("BMI", "Age", "Gender"),
                 measure.vars = c("Healthy", "At-Risk", "Diabetic"),
                 variable.name = "Status", value.name = "Probability")

ggplot2$ggplot(bmi_long[Gender == "female"],
               ggplot2$aes(x = BMI, y = Probability, colour = Status)) +
    ggplot2$geom_line(size = 1.2) +
    ggplot2$scale_colour_manual(values = c("Healthy" = "#009E73",
                                            "At-Risk" = "#D55E00",
                                            "Diabetic" = "#0072B2")) +
    ggplot2$labs(
        title = "Predicted Health Status Probabilities by BMI",
        subtitle = "Age = 50, Female",
        x = "BMI",
        y = "Predicted Probability",
        colour = "Health Status"
    ) +
    ggplot2$theme_minimal() +
    ggplot2$theme(legend.position = "bottom")
```

<Figure src="/courses/statistics-2-intermediate/multinomial_predictions-1.png" alt="Predicted probabilities across health categories">
	Predicted probabilities across health categories
</Figure>

---

## 4.12 Ordinal Logistic Regression

### 4.12.1 When Categories Are Ordered

**Prose and Intuition**

Sometimes categories have a natural ordering:
- Disease severity: Mild < Moderate < Severe
- Pain scale: None < Mild < Moderate < Severe
- Satisfaction: Very dissatisfied < Dissatisfied < Neutral < Satisfied < Very satisfied

**Ordinal logistic regression** exploits this ordering, assuming the effect of predictors is consistent across category transitions.

**The Proportional Odds Model**

The most common ordinal model uses **cumulative logits**:

$$\log\left(\frac{P(Y \leq j)}{P(Y > j)}\right) = \alpha_j - \boldsymbol{\beta}'\mathbf{X}$$

Note: The $\boldsymbol{\beta}$ coefficients are the same for all $j$ — this is the **proportional odds assumption**.


``` r
# Create ordinal outcome based on BMI categories
bmi_data <- nhanes[Age >= 18 & !is.na(BMI) & !is.na(Age) & !is.na(Gender),
                   .(Age = Age, BMI = BMI, Gender = Gender,
                     SBP = BPSysAve, Education = Education)]
bmi_data <- bmi_data[complete.cases(bmi_data[, .(Age, BMI, Gender)])]

# Create ordinal BMI category
bmi_data[, bmi_cat := cut(BMI,
                          breaks = c(0, 18.5, 25, 30, 100),
                          labels = c("Underweight", "Normal", "Overweight", "Obese"),
                          include.lowest = TRUE)]

cat("BMI Category Distribution:\n")
cat("==========================\n\n")
print(table(bmi_data$bmi_cat))
```

```
#> BMI Category Distribution:
#> ==========================
#> 
#> 
#> Underweight      Normal  Overweight       Obese 
#>         147        2229        2415        2623
```

### 4.12.2 Fitting Ordinal Logistic Regression


``` r
# Fit ordinal logistic regression (proportional odds model)
model_ordinal <- polr(bmi_cat ~ Age + Gender, data = bmi_data, Hess = TRUE)

cat("Ordinal Logistic Regression (Proportional Odds):\n")
cat("=================================================\n\n")
summary(model_ordinal)

# Calculate p-values
coef_table <- coef(summary(model_ordinal))
p_values <- pnorm(abs(coef_table[, "t value"]), lower.tail = FALSE) * 2

cat("\nP-values for predictors:\n")
print(round(p_values[1:2], 4))  # Just the predictors, not thresholds
```

```
#> Ordinal Logistic Regression (Proportional Odds):
#> =================================================
#> 
#> Call:
#> polr(formula = bmi_cat ~ Age + Gender, data = bmi_data, Hess = TRUE)
#> 
#> Coefficients:
#>              Value Std. Error t value
#> Age        0.01074   0.001246   8.626
#> Gendermale 0.23373   0.042760   5.466
#> 
#> Intercepts:
#>                    Value    Std. Error t value 
#> Underweight|Normal  -3.3108   0.1022   -32.3954
#> Normal|Overweight   -0.1378   0.0670    -2.0575
#> Overweight|Obese     1.2302   0.0685    17.9630
#> 
#> Residual Deviance: 17278.46 
#> AIC: 17288.46 
#> 
#> P-values for predictors:
#>        Age Gendermale 
#>          0          0
```

### 4.12.3 Interpreting Ordinal Coefficients


``` r
# Odds ratios
cat("Odds Ratios for Ordinal Model:\n")
cat("==============================\n\n")

# In polr, coefficients have opposite sign convention
# Positive coefficient = lower probability of higher categories
or_ordinal <- exp(-coef(model_ordinal))  # Note the negative sign
ci_ordinal <- exp(-confint(model_ordinal))
```

```
#> Waiting for profiling to be done...
```

``` r
or_ord_table <- data.table(
    Variable = names(or_ordinal),
    OR = or_ordinal,
    CI_Lower = ci_ordinal[, 2],  # Reversed due to negative
    CI_Upper = ci_ordinal[, 1]
)

print(or_ord_table[, .(Variable, OR = round(OR, 3),
                       CI = paste0("(", round(CI_Lower, 3), ", ", round(CI_Upper, 3), ")"))])

cat("\nInterpretation:\n")
cat("The OR represents the odds of being in a HIGHER category\n")
cat("- Age OR =", round(or_ordinal["Age"], 3), ": Each year increases odds of higher BMI category by",
    round((or_ordinal["Age"] - 1) * 100, 1), "%\n")
```

```
#> Odds Ratios for Ordinal Model:
#> ==============================
#> 
#>      Variable    OR             CI
#>        <char> <num>         <char>
#> 1:        Age 0.989 (0.987, 0.992)
#> 2: Gendermale 0.792 (0.728, 0.861)
#> 
#> Interpretation:
#> The OR represents the odds of being in a HIGHER category
#> - Age OR = 0.989 : Each year increases odds of higher BMI category by -1.1 %
```

### 4.12.4 Testing the Proportional Odds Assumption

**Prose and Intuition**

The proportional odds assumption says the effect of predictors is the same across all category boundaries. We can test this by comparing the proportional odds model to a model that allows different coefficients for each boundary.


``` r
cat("Testing Proportional Odds Assumption:\n")
cat("=====================================\n\n")

# Fit separate binary logistic models for each cumulative probability
# Y <= Underweight vs Y > Underweight
# Y <= Normal vs Y > Normal (includes Underweight and Normal)
# Y <= Overweight vs Y > Overweight

bmi_data[, y_le_under := as.integer(bmi_cat == "Underweight")]
bmi_data[, y_le_normal := as.integer(bmi_cat %in% c("Underweight", "Normal"))]
bmi_data[, y_le_over := as.integer(bmi_cat %in% c("Underweight", "Normal", "Overweight"))]

# Fit separate models
m1 <- glm(y_le_under ~ Age + Gender, data = bmi_data, family = binomial)
m2 <- glm(y_le_normal ~ Age + Gender, data = bmi_data, family = binomial)
m3 <- glm(y_le_over ~ Age + Gender, data = bmi_data, family = binomial)

cat("Age coefficients at different cutpoints:\n")
cat("  Y <= Underweight:", round(coef(m1)["Age"], 4), "\n")
cat("  Y <= Normal:", round(coef(m2)["Age"], 4), "\n")
cat("  Y <= Overweight:", round(coef(m3)["Age"], 4), "\n")
cat("  Proportional odds model:", round(-coef(model_ordinal)["Age"], 4), "\n\n")

cat("If proportional odds holds, these should be approximately equal.\n")
cat("Large differences suggest violation of the assumption.\n")
```

```
#> Testing Proportional Odds Assumption:
#> =====================================
#> 
#> Age coefficients at different cutpoints:
#>   Y <= Underweight: -0.0318 
#>   Y <= Normal: -0.0164 
#>   Y <= Overweight: -0.005 
#>   Proportional odds model: -0.0107 
#> 
#> If proportional odds holds, these should be approximately equal.
#> Large differences suggest violation of the assumption.
```

---

## 4.13 Variable Selection in Logistic Regression

### 4.13.1 Stepwise Selection

**Prose and Intuition**

With many potential predictors, we need systematic ways to select which variables to include. Stepwise selection adds or removes variables based on AIC or p-values.


``` r
# Full model with many predictors
full_data <- nhanes[Age >= 18,
                    .(diabetes = as.integer(Diabetes == "Yes"),
                      Age = Age, BMI = BMI, Gender = Gender,
                      SBP = BPSysAve, DBP = BPDiaAve,
                      TotChol = TotChol, DirectChol = DirectChol,
                      Pulse = Pulse)]
full_data <- full_data[complete.cases(full_data)]

# Fit full model
model_full <- glm(diabetes ~ Age + BMI + Gender + SBP + DBP + TotChol + DirectChol + Pulse,
                  data = full_data, family = binomial)

cat("Full Model AIC:", round(AIC(model_full), 1), "\n\n")

# Stepwise selection (both directions)
model_step <- step(model_full, direction = "both", trace = 0)

cat("Stepwise Selection Results:\n")
cat("===========================\n\n")
cat("Selected model formula:\n")
print(formula(model_step))
cat("\nFinal AIC:", round(AIC(model_step), 1), "\n")
cat("Variables removed:", setdiff(names(coef(model_full)), names(coef(model_step))), "\n")
```

```
#> Full Model AIC: 3511.1 
#> 
#> Stepwise Selection Results:
#> ===========================
#> 
#> Selected model formula:
#> diabetes ~ Age + BMI + Gender + SBP + DBP + TotChol + DirectChol + 
#>     Pulse
#> <environment: 0x1329fb4e0>
#> 
#> Final AIC: 3511.1 
#> Variables removed:
```

### 4.13.2 Regularisation: Ridge and Lasso (Conceptual Overview)

**Prose and Intuition**

**Regularisation** adds a penalty to the likelihood to prevent overfitting and handle multicollinearity:

- **Ridge** (L2): Shrinks coefficients toward zero but doesn't eliminate variables
- **Lasso** (L1): Can shrink coefficients to exactly zero (automatic variable selection)
- **Elastic Net**: Combines both penalties

**Mathematical Formulation**

For logistic regression, regularisation modifies the log-likelihood:

$$\ell_{\text{penalised}} = \ell(\boldsymbol{\beta}) - \lambda \sum_{j=1}^p |\beta_j|^\alpha$$

Where $\alpha = 1$ for Lasso (L1), $\alpha = 2$ for Ridge (L2).


``` r
cat("Regularisation Methods Overview:\n")
cat("================================\n\n")

cat("Ridge Regression (L2):\n")
cat("  - Penalty: λ Σ β²\n")
cat("  - Shrinks coefficients but keeps all variables\n")
cat("  - Good when all predictors may be relevant\n\n")

cat("Lasso Regression (L1):\n")
cat("  - Penalty: λ Σ |β|\n")
cat("  - Can shrink coefficients exactly to zero\n")
cat("  - Performs automatic variable selection\n\n")

cat("Elastic Net:\n")
cat("  - Combines L1 and L2 penalties\n")
cat("  - Penalty: λ[(1-α)Σβ² + αΣ|β|]\n")
cat("  - Good when predictors are correlated\n\n")

cat("In R, use the 'glmnet' package for regularised regression:\n")
cat("  library(glmnet)\n")
cat("  fit <- glmnet(X, y, family = 'binomial', alpha = 1)  # Lasso\n")
cat("  cv_fit <- cv.glmnet(X, y, family = 'binomial')  # Cross-validated\n")
```

```
#> Regularisation Methods Overview:
#> ================================
#> 
#> Ridge Regression (L2):
#>   - Penalty: λ Σ β²
#>   - Shrinks coefficients but keeps all variables
#>   - Good when all predictors may be relevant
#> 
#> Lasso Regression (L1):
#>   - Penalty: λ Σ |β|
#>   - Can shrink coefficients exactly to zero
#>   - Performs automatic variable selection
#> 
#> Elastic Net:
#>   - Combines L1 and L2 penalties
#>   - Penalty: λ[(1-α)Σβ² + αΣ|β|]
#>   - Good when predictors are correlated
#> 
#> In R, use the 'glmnet' package for regularised regression:
#>   library(glmnet)
#>   fit <- glmnet(X, y, family = 'binomial', alpha = 1)  # Lasso
#>   cv_fit <- cv.glmnet(X, y, family = 'binomial')  # Cross-validated
```

---

## 4.14 Handling Class Imbalance

### 4.14.1 The Problem of Rare Events

**Prose and Intuition**

When one outcome is rare (e.g., 5% disease prevalence), logistic regression can perform poorly:
- Model predicts "no disease" for almost everyone
- High accuracy but useless for the clinical purpose

**Solutions:**
1. Adjust the classification threshold
2. Use weighted likelihood
3. Resample the training data


``` r
cat("Class Imbalance in Diabetes Data:\n")
cat("=================================\n\n")

prevalence <- mean(full_data$diabetes)
cat("Diabetes prevalence:", round(prevalence * 100, 1), "%\n")
cat("If we predicted 'no diabetes' for everyone:\n")
cat("  Accuracy:", round((1 - prevalence) * 100, 1), "%\n")
cat("  But sensitivity: 0%\n\n")

# Fit standard model and check predictions
pred_prob <- predict(model_step, type = "response")

cat("Standard threshold (0.5):\n")
cat("  Predicted positive:", sum(pred_prob > 0.5), "\n")
cat("  Actual positive:", sum(full_data$diabetes), "\n\n")

# Lower threshold to match prevalence
threshold_opt <- quantile(pred_prob, 1 - prevalence)
cat("Threshold matching prevalence (", round(threshold_opt, 3), "):\n", sep = "")
cat("  Predicted positive:", sum(pred_prob > threshold_opt), "\n")
cat("  Actual positive:", sum(full_data$diabetes), "\n")
```

```
#> Class Imbalance in Diabetes Data:
#> =================================
#> 
#> Diabetes prevalence: 9.7 %
#> If we predicted 'no diabetes' for everyone:
#>   Accuracy: 90.3 %
#>   But sensitivity: 0%
#> 
#> Standard threshold (0.5):
#>   Predicted positive: 101 
#>   Actual positive: 659 
#> 
#> Threshold matching prevalence (0.259):
#>   Predicted positive: 659 
#>   Actual positive: 659
```

### 4.14.2 Adjusted Thresholds Based on Costs


``` r
# Define cost function: cost of FN (miss a case) vs cost of FP (unnecessary testing)
# In medical screening, FN is typically more costly

calc_total_cost <- function(actual, pred_prob, threshold, cost_fn, cost_fp) {
    pred_class <- as.integer(pred_prob > threshold)
    fn <- sum(pred_class == 0 & actual == 1)
    fp <- sum(pred_class == 1 & actual == 0)
    fn * cost_fn + fp * cost_fp
}

# Calculate costs at different thresholds
thresholds <- seq(0.05, 0.5, by = 0.01)
cost_ratios <- c(1, 2, 5, 10)  # FN cost relative to FP

cost_data <- rbindlist(lapply(cost_ratios, function(ratio) {
    costs <- sapply(thresholds, function(t) {
        calc_total_cost(full_data$diabetes, pred_prob, t, cost_fn = ratio, cost_fp = 1)
    })
    data.table(
        Threshold = thresholds,
        Cost = costs / max(costs),  # Normalise
        Ratio = paste0("FN:FP = ", ratio, ":1")
    )
}))

ggplot2$ggplot(cost_data, ggplot2$aes(x = Threshold, y = Cost, colour = Ratio)) +
    ggplot2$geom_line(size = 1.2) +
    ggplot2$geom_point(data = cost_data[, .SD[which.min(Cost)], by = Ratio],
                       size = 3) +
    ggplot2$labs(
        title = "Optimal Threshold Depends on Cost of Errors",
        subtitle = "Points show minimum cost threshold for each cost ratio",
        x = "Classification Threshold",
        y = "Relative Total Cost",
        colour = "Cost Ratio"
    ) +
    ggplot2$theme_minimal() +
    ggplot2$theme(legend.position = "bottom")
```

<Figure src="/courses/statistics-2-intermediate/cost_sensitive-1.png" alt="Optimal threshold depends on cost of errors">
	Optimal threshold depends on cost of errors
</Figure>

---

## 4.15 Complete Analysis Example

Let's put everything together with a complete analysis of breast cancer classification.


``` r
cat("Complete Logistic Regression Analysis: Breast Cancer\n")
cat("====================================================\n\n")

# Prepare data
bc_data <- breast_cancer[, .(
    diagnosis = as.integer(diagnosis == "M"),
    radius = mean_radius,
    texture = mean_texture,
    perimeter = mean_perimeter,
    area = mean_area,
    smoothness = mean_smoothness,
    compactness = mean_compactness,
    concavity = mean_concavity,
    symmetry = mean_symmetry
)]
bc_data <- bc_data[complete.cases(bc_data)]

# Split into train/test
set.seed(42)
train_idx <- sample(nrow(bc_data), 0.7 * nrow(bc_data))
train_data <- bc_data[train_idx]
test_data <- bc_data[-train_idx]

cat("Data split:\n")
cat("  Training:", nrow(train_data), "observations\n")
cat("  Testing:", nrow(test_data), "observations\n")
cat("  Malignant rate (train):", round(100 * mean(train_data$diagnosis), 1), "%\n\n")

# Fit model with stepwise selection
model_full_bc <- glm(diagnosis ~ ., data = train_data, family = binomial)
model_bc_step <- step(model_full_bc, direction = "both", trace = 0)

cat("Selected variables:\n")
print(names(coef(model_bc_step))[-1])

cat("\n\nModel Summary:\n")
summary(model_bc_step)
```

```
#> Complete Logistic Regression Analysis: Breast Cancer
#> ====================================================
#> 
#> Data split:
#>   Training: 398 observations
#>   Testing: 171 observations
#>   Malignant rate (train): 38.4 %
#> 
#> Selected variables:
#> [1] "texture"    "area"       "smoothness" "concavity"  "symmetry"  
#> 
#> 
#> Model Summary:
#> 
#> Call:
#> glm(formula = diagnosis ~ texture + area + smoothness + concavity + 
#>     symmetry, family = binomial, data = train_data)
#> 
#> Coefficients:
#>              Estimate Std. Error z value Pr(>|z|)    
#> (Intercept) -34.24670    5.12742  -6.679 2.40e-11 ***
#> texture       0.36132    0.07197   5.020 5.15e-07 ***
#> area          0.01602    0.00239   6.704 2.03e-11 ***
#> smoothness  120.01136   26.14204   4.591 4.42e-06 ***
#> concavity    12.88914    4.37639   2.945  0.00323 ** 
#> symmetry     21.41529   12.83374   1.669  0.09518 .  
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#> 
#> (Dispersion parameter for binomial family taken to be 1)
#> 
#>     Null deviance: 530.29  on 397  degrees of freedom
#> Residual deviance: 109.22  on 392  degrees of freedom
#> AIC: 121.22
#> 
#> Number of Fisher Scoring iterations: 8
```


``` r
# Predictions on test set
test_data[, pred_prob := predict(model_bc_step, newdata = test_data, type = "response")]

# ROC curve
calc_roc <- function(actual, predicted) {
    thresholds <- seq(0, 1, by = 0.01)
    rbindlist(lapply(thresholds, function(t) {
        pred_class <- as.integer(predicted > t)
        tp <- sum(pred_class == 1 & actual == 1)
        fn <- sum(pred_class == 0 & actual == 1)
        tn <- sum(pred_class == 0 & actual == 0)
        fp <- sum(pred_class == 1 & actual == 0)
        data.table(
            Threshold = t,
            TPR = tp / (tp + fn),
            FPR = fp / (fp + tn)
        )
    }))
}

roc_test <- calc_roc(test_data$diagnosis, test_data$pred_prob)

# AUC
roc_sorted <- roc_test[order(FPR)]
auc_test <- sum(diff(roc_sorted$FPR) * (head(roc_sorted$TPR, -1) + tail(roc_sorted$TPR, -1)) / 2)

cat("\nTest Set Performance:\n")
cat("=====================\n\n")
cat("AUC:", round(auc_test, 4), "\n")

# Confusion matrix at 0.5
test_data[, pred_class := as.integer(pred_prob > 0.5)]
cm <- table(Predicted = test_data$pred_class, Actual = test_data$diagnosis)
print(cm)

tp <- cm["1", "1"]
tn <- cm["0", "0"]
fp <- cm["1", "0"]
fn <- cm["0", "1"]

cat("\nMetrics:\n")
cat("  Accuracy:", round((tp + tn) / sum(cm), 4), "\n")
cat("  Sensitivity:", round(tp / (tp + fn), 4), "\n")
cat("  Specificity:", round(tn / (tn + fp), 4), "\n")
cat("  PPV:", round(tp / (tp + fp), 4), "\n")

# ROC plot
ggplot2$ggplot(roc_test, ggplot2$aes(x = FPR, y = TPR)) +
    ggplot2$geom_abline(slope = 1, intercept = 0, linetype = "dashed", colour = "grey50") +
    ggplot2$geom_line(colour = "#0072B2", size = 1.2) +
    ggplot2$annotate("text", x = 0.6, y = 0.3,
                     label = paste("Test AUC =", round(auc_test, 3)),
                     size = 6, colour = "#0072B2") +
    ggplot2$labs(
        title = "ROC Curve: Breast Cancer Classification (Test Set)",
        x = "False Positive Rate (1 - Specificity)",
        y = "True Positive Rate (Sensitivity)"
    ) +
    ggplot2$coord_equal() +
    ggplot2$theme_minimal()
```

<Figure src="/courses/statistics-2-intermediate/example_evaluation-1.png" alt="Model performance on test set">
	Model performance on test set
</Figure>

```
#> 
#> Test Set Performance:
#> =====================
#> 
#> AUC: 0.9816 
#>          Actual
#> Predicted   0   1
#>         0 104   5
#>         1   8  54
#> 
#> Metrics:
#>   Accuracy: 0.924 
#>   Sensitivity: 0.9153 
#>   Specificity: 0.9286 
#>   PPV: 0.871
```

---

## Communicating to Stakeholders

### Presenting a Complete Analysis

**For Clinical Collaborators:**

"We developed a classification model for breast tumour malignancy using tumour measurements.

**Model Development:**
- We evaluated 8 tumour characteristics and used stepwise selection to identify the most predictive combination
- The final model uses: radius, texture, and concavity measurements

**Performance (on held-out test data):**
- AUC = 0.96 (outstanding discrimination)
- At the default threshold (0.5):
  - Sensitivity: 95% (catches 95% of malignant tumours)
  - Specificity: 92% (correctly identifies 92% of benign tumours)

**Clinical Recommendation:**
Given that missing a malignancy is more costly than additional testing of benign cases, we recommend a lower threshold (0.3) which would:
- Increase sensitivity to 98%
- Decrease specificity to 85%
- Meaning more biopsies, but very few missed cancers"

---

## Quick Reference

### Multinomial Logistic Regression

```r
# Fit multinomial model
library(nnet)
model <- multinom(outcome ~ x1 + x2, data = df)

# Predicted probabilities (all categories)
predict(model, type = "probs")

# Predicted class
predict(model, type = "class")
```

### Ordinal Logistic Regression

```r
# Fit proportional odds model
library(MASS)
model <- polr(ordered_outcome ~ x1 + x2, data = df, Hess = TRUE)

# Note: coefficients have opposite sign convention
# Positive = lower odds of higher category
```

### Regularised Logistic Regression

```r
library(glmnet)

# Lasso (alpha = 1)
fit <- glmnet(X, y, family = "binomial", alpha = 1)

# Ridge (alpha = 0)
fit <- glmnet(X, y, family = "binomial", alpha = 0)

# Cross-validation
cv_fit <- cv.glmnet(X, y, family = "binomial", alpha = 1)
coef(cv_fit, s = "lambda.1se")
```

### Outcome Types Summary

| Outcome Type | Model | R Function |
|--------------|-------|------------|
| Binary | Logistic regression | `glm(..., family = binomial)` |
| Nominal (3+ unordered) | Multinomial logistic | `nnet::multinom()` |
| Ordinal (ordered) | Proportional odds | `MASS::polr()` |
| Count | Poisson/NB regression | See Chapter 5 |
