---
title: "Statistics with R III: Advanced"
chapter: "Chapter 6: Resampling Methods"
part: "Part 2: Permutation Tests and Jackknife"
coverImage: 13
author: "Dereck Mezquita"
date: "2026-01-19"
tags: [statistics, resampling, permutation-tests, jackknife, R, biomedical]
published: true
comments: true
output:
  html_document:
    keep_md: true
---



# Part 2: Permutation Tests and Jackknife

While the bootstrap estimates sampling distributions, **permutation tests** provide exact hypothesis tests under the null. The **jackknife** predates the bootstrap and offers bias estimation and influence analysis. This chapter completes our resampling toolkit with these complementary methods.


``` r
box::use(
    data.table[...],
    ggplot2
)

set.seed(42)
```


``` r
# Load breast cancer dataset
breast_cancer <- fread("../../../data/bioinformatics/breast_cancer_wisconsin.csv")
breast_cancer[, diagnosis := factor(diagnosis, levels = c("B", "M"),
                                     labels = c("Benign", "Malignant"))]

cat("Dataset Summary\n")
#> Dataset Summary
cat("===============\n")
#> ===============
cat("  Total samples:", nrow(breast_cancer), "\n")
#>   Total samples: 569
cat("  Benign:", sum(breast_cancer$diagnosis == "Benign"), "\n")
#>   Benign: 357
cat("  Malignant:", sum(breast_cancer$diagnosis == "Malignant"), "\n")
#>   Malignant: 212
```

---

## 6.8 Permutation Tests

### 6.8.1 The Permutation Principle

**Prose and Intuition**

**Permutation tests** (also called randomisation tests or exact tests) test hypotheses by asking: "If the null hypothesis were true, how likely is the observed test statistic?"

Under the null (no difference between groups), group labels are exchangeableâ€”we could shuffle them without changing the distribution. The permutation test:
1. Computes the observed test statistic
2. Generates the null distribution by permuting group labels
3. Calculates the p-value as the proportion of permutations at least as extreme as observed

**Key insight**: The permutation distribution is the **exact** null distribution under the hypothesis of exchangeability.

**Mathematical Framework**

For a two-sample test comparing groups A and B:

**Null hypothesis**: $H_0: F_A = F_B$ (same distribution)

Under $H_0$, any assignment of observations to groups is equally likely. With $n_A + n_B = n$ observations, there are $\binom{n}{n_A}$ possible assignments.

The **permutation p-value**:
$$p = \frac{\#\{T^* \geq T_{obs}\}}{\text{total permutations}}$$


``` r
# Two-sample permutation test: compare mean_radius between diagnoses
benign <- breast_cancer[diagnosis == "Benign"]$mean_radius
malignant <- breast_cancer[diagnosis == "Malignant"]$mean_radius

# Observed test statistic
obs_diff <- mean(malignant) - mean(benign)

# Pool all data
pooled <- c(benign, malignant)
n_benign <- length(benign)
n_malignant <- length(malignant)
n_total <- n_benign + n_malignant

# Permutation test
n_perm <- 10000
perm_diffs <- numeric(n_perm)

for (p in 1:n_perm) {
    # Shuffle labels
    shuffled <- sample(pooled)
    perm_benign <- shuffled[1:n_benign]
    perm_malignant <- shuffled[(n_benign + 1):n_total]

    perm_diffs[p] <- mean(perm_malignant) - mean(perm_benign)
}

# P-value (two-sided)
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))

cat("Permutation Test: Mean Radius by Diagnosis\n")
#> Permutation Test: Mean Radius by Diagnosis
cat("==========================================\n")
#> ==========================================
cat("  Mean (Benign):", round(mean(benign), 3), "\n")
#>   Mean (Benign): 12.147
cat("  Mean (Malignant):", round(mean(malignant), 3), "\n")
#>   Mean (Malignant): 17.463
cat("  Observed difference:", round(obs_diff, 3), "\n")
#>   Observed difference: 5.316
cat("  Permutation p-value:", format.pval(p_value, digits = 4), "\n")
#>   Permutation p-value: < 2.2e-16

# Compare to t-test
t_result <- t.test(malignant, benign)
cat("  T-test p-value:", format.pval(t_result$p.value, digits = 4), "\n")
#>   T-test p-value: < 2.2e-16

# Visualise null distribution
perm_data <- data.table(difference = perm_diffs)

ggplot2$ggplot(perm_data, ggplot2$aes(x = difference)) +
    ggplot2$geom_histogram(ggplot2$aes(y = ..density..),
                            bins = 50, fill = "grey70", alpha = 0.8) +
    ggplot2$geom_density(colour = "#2166AC", linewidth = 1) +
    ggplot2$geom_vline(xintercept = obs_diff, colour = "#D95F02",
                        linewidth = 1.2, linetype = "solid") +
    ggplot2$geom_vline(xintercept = -obs_diff, colour = "#D95F02",
                        linewidth = 1.2, linetype = "dashed") +
    ggplot2$annotate("text", x = obs_diff + 0.3, y = 0.5,
                      label = paste("Observed =", round(obs_diff, 2)),
                      colour = "#D95F02", fontface = "bold", hjust = 0) +
    ggplot2$labs(
        title = "Permutation Null Distribution",
        subtitle = paste0("p-value = ", format.pval(p_value, digits = 4),
                         " (", n_perm, " permutations)"),
        x = "Difference in Means (Malignant - Benign)",
        y = "Density"
    ) +
    ggplot2$theme_minimal(base_size = 14) +
    ggplot2$theme(plot.title = ggplot2$element_text(face = "bold"))
```

<Figure src="permutation_principle-1.png" alt="Permutation test: generating the null distribution by shuffling labels">
	Permutation test: generating the null distribution by shuffling labels
</Figure>

### 6.8.2 Permutation Test for Correlation

**Prose and Intuition**

To test whether two variables are associated, we can permute one variable while keeping the other fixed. Under the null of no association, the pairing is arbitrary.


``` r
# Test correlation between mean_radius and mean_texture
x <- breast_cancer$mean_radius
y <- breast_cancer$mean_texture

# Observed correlation
obs_cor <- cor(x, y)

# Permutation test (permute y)
n_perm <- 10000
perm_cors <- numeric(n_perm)

for (p in 1:n_perm) {
    y_perm <- sample(y)
    perm_cors[p] <- cor(x, y_perm)
}

# P-value
p_value_cor <- mean(abs(perm_cors) >= abs(obs_cor))

cat("Permutation Test for Correlation:\n")
#> Permutation Test for Correlation:
cat("==================================\n")
#> ==================================
cat("  Observed r:", round(obs_cor, 4), "\n")
#>   Observed r: 0.3238
cat("  Permutation p-value:", format.pval(p_value_cor, digits = 4), "\n")
#>   Permutation p-value: < 2.2e-16

# Compare to parametric test
cor_test <- cor.test(x, y)
cat("  Parametric p-value:", format.pval(cor_test$p.value, digits = 4), "\n")
#>   Parametric p-value: 2.36e-15

# Visualise
cor_perm_data <- data.table(correlation = perm_cors)

ggplot2$ggplot(cor_perm_data, ggplot2$aes(x = correlation)) +
    ggplot2$geom_histogram(ggplot2$aes(y = ..density..),
                            bins = 50, fill = "grey70", alpha = 0.8) +
    ggplot2$geom_density(colour = "#2166AC", linewidth = 1) +
    ggplot2$geom_vline(xintercept = obs_cor, colour = "#D95F02", linewidth = 1.2) +
    ggplot2$geom_vline(xintercept = -obs_cor, colour = "#D95F02",
                        linewidth = 1.2, linetype = "dashed") +
    ggplot2$labs(
        title = "Permutation Null Distribution for Correlation",
        subtitle = paste0("Observed r = ", round(obs_cor, 3),
                         ", p = ", format.pval(p_value_cor, digits = 4)),
        x = "Correlation",
        y = "Density"
    ) +
    ggplot2$theme_minimal(base_size = 14) +
    ggplot2$theme(plot.title = ggplot2$element_text(face = "bold"))
```

<Figure src="permutation_correlation-1.png" alt="Permutation test for correlation coefficient">
	Permutation test for correlation coefficient
</Figure>

### 6.8.3 Permutation Test for Regression

**Prose and Intuition**

For regression, we test whether covariates predict the response. Under the null, there's no relationship, so we can permute the response variable.

This tests the **global null** that all coefficients (except intercept) are zero.


``` r
# Regression: predict mean_radius from texture, perimeter, smoothness
reg_data <- breast_cancer[, .(mean_radius, mean_texture, mean_perimeter, mean_smoothness)]

# Original fit
fit <- lm(mean_radius ~ mean_texture + mean_perimeter + mean_smoothness, data = reg_data)

# Observed F-statistic
obs_F <- summary(fit)$fstatistic[1]

# Permutation test (permute response)
n_perm <- 5000
perm_F <- numeric(n_perm)

for (p in 1:n_perm) {
    reg_data_perm <- copy(reg_data)
    reg_data_perm[, mean_radius := sample(mean_radius)]

    fit_perm <- lm(mean_radius ~ mean_texture + mean_perimeter + mean_smoothness,
                   data = reg_data_perm)
    perm_F[p] <- summary(fit_perm)$fstatistic[1]
}

p_value_F <- mean(perm_F >= obs_F)

cat("Permutation Test for Regression F-statistic:\n")
#> Permutation Test for Regression F-statistic:
cat("============================================\n")
#> ============================================
cat("  Observed F:", round(obs_F, 2), "\n")
#>   Observed F: 66374.7
cat("  Permutation p-value:", format.pval(p_value_F, digits = 4), "\n")
#>   Permutation p-value: < 2.2e-16

# Compare to parametric
param_p <- pf(summary(fit)$fstatistic[1],
              summary(fit)$fstatistic[2],
              summary(fit)$fstatistic[3],
              lower.tail = FALSE)
cat("  Parametric p-value:", format.pval(param_p, digits = 4), "\n")
#>   Parametric p-value: < 2.2e-16

# Visualise
F_perm_data <- data.table(F_stat = perm_F)

ggplot2$ggplot(F_perm_data, ggplot2$aes(x = F_stat)) +
    ggplot2$geom_histogram(ggplot2$aes(y = ..density..),
                            bins = 50, fill = "grey70", alpha = 0.8) +
    ggplot2$geom_density(colour = "#2166AC", linewidth = 1) +
    ggplot2$geom_vline(xintercept = obs_F, colour = "#D95F02", linewidth = 1.2) +
    ggplot2$xlim(c(0, max(c(perm_F, obs_F)) * 1.1)) +
    ggplot2$labs(
        title = "Permutation Null Distribution for F-statistic",
        subtitle = paste0("Observed F = ", round(obs_F, 1),
                         ", p = ", format.pval(p_value_F, digits = 4)),
        x = "F-statistic",
        y = "Density"
    ) +
    ggplot2$theme_minimal(base_size = 14) +
    ggplot2$theme(plot.title = ggplot2$element_text(face = "bold"))
```

<Figure src="permutation_regression-1.png" alt="Permutation test for regression F-statistic">
	Permutation test for regression F-statistic
</Figure>

### 6.8.4 Exact vs Monte Carlo Permutation Tests

**Prose and Intuition**

For small samples, we can enumerate **all** possible permutations for an **exact** test. For larger samples, we use **Monte Carlo** approximation.

**Exact permutation**:
- For $n_1 + n_2 = 10$ with $n_1 = 5$: only $\binom{10}{5} = 252$ permutations
- Enumerate all and compute exact p-value

**Monte Carlo**:
- Sample from the permutation distribution
- P-value is approximate with Monte Carlo error


``` r
# Small sample example: exact permutation test
set.seed(123)
group_a <- rnorm(5, mean = 0, sd = 1)
group_b <- rnorm(5, mean = 1, sd = 1)

pooled_small <- c(group_a, group_b)
n_a <- length(group_a)
n_total_small <- length(pooled_small)

# Observed statistic
obs_diff_small <- mean(group_b) - mean(group_a)

# Generate all permutations
library(gtools)  # for combinations
#> 
#> Attaching package: 'gtools'
#> The following object is masked from 'package:car':
#> 
#>     logit
#> The following object is masked from 'package:glmnet':
#> 
#>     na.replace
all_combs <- combinations(n_total_small, n_a)

n_exact <- nrow(all_combs)
exact_diffs <- numeric(n_exact)

for (i in 1:n_exact) {
    idx_a <- all_combs[i, ]
    exact_diffs[i] <- mean(pooled_small[-idx_a]) - mean(pooled_small[idx_a])
}

# Exact p-value
p_exact <- mean(abs(exact_diffs) >= abs(obs_diff_small))

cat("Exact Permutation Test (Small Sample):\n")
#> Exact Permutation Test (Small Sample):
cat("======================================\n")
#> ======================================
cat("  Sample sizes:", n_a, "+", n_total_small - n_a, "\n")
#>   Sample sizes: 5 + 5
cat("  Total permutations:", n_exact, "\n")
#>   Total permutations: 252
cat("  Observed difference:", round(obs_diff_small, 3), "\n")
#>   Observed difference: 0.762
cat("  Exact p-value:", round(p_exact, 4), "\n")
#>   Exact p-value: 0.254

# Compare to Monte Carlo
n_mc <- 10000
mc_diffs <- replicate(n_mc, {
    idx <- sample(1:n_total_small, n_a)
    mean(pooled_small[-idx]) - mean(pooled_small[idx])
})
p_mc <- mean(abs(mc_diffs) >= abs(obs_diff_small))
cat("  Monte Carlo p-value (B=10000):", round(p_mc, 4), "\n")
#>   Monte Carlo p-value (B=10000): 0.2499
```

---

## 6.9 The Jackknife

### 6.9.1 Leave-One-Out Resampling

**Prose and Intuition**

The **jackknife** (Quenouille 1949, Tukey 1958) predates the bootstrap. It systematically leaves out one observation at a time:

For sample $X_1, \ldots, X_n$, compute:
- $\hat{\theta}_{(-i)}$ = statistic with observation $i$ removed

The **jackknife pseudo-values** are:
$$\tilde{\theta}_i = n\hat{\theta} - (n-1)\hat{\theta}_{(-i)}$$

**Jackknife estimate of variance**:
$$\widehat{Var}_{jack}(\hat{\theta}) = \frac{n-1}{n}\sum_{i=1}^{n}(\hat{\theta}_{(-i)} - \bar{\theta}_{(\cdot)})^2$$

where $\bar{\theta}_{(\cdot)} = \frac{1}{n}\sum_{i=1}^{n}\hat{\theta}_{(-i)}$.

**Mathematical Framework**

The jackknife estimates the **bias**:
$$\widehat{Bias}_{jack} = (n-1)(\bar{\theta}_{(\cdot)} - \hat{\theta})$$

**Bias-corrected estimate**:
$$\hat{\theta}_{jack} = \hat{\theta} - \widehat{Bias}_{jack} = n\hat{\theta} - (n-1)\bar{\theta}_{(\cdot)}$$


``` r
# Jackknife for variance estimate
x <- breast_cancer$mean_radius[1:100]  # Use subset for demonstration
n <- length(x)

# Original estimate
theta_hat <- var(x)

# Leave-one-out estimates
theta_loo <- numeric(n)
for (i in 1:n) {
    theta_loo[i] <- var(x[-i])
}

# Jackknife variance estimate
theta_bar <- mean(theta_loo)
var_jack <- ((n - 1) / n) * sum((theta_loo - theta_bar)^2)
se_jack <- sqrt(var_jack)

# Jackknife bias estimate
bias_jack <- (n - 1) * (theta_bar - theta_hat)

# Bias-corrected estimate
theta_jack <- theta_hat - bias_jack

cat("Jackknife Analysis of Variance Estimator:\n")
#> Jackknife Analysis of Variance Estimator:
cat("=========================================\n")
#> =========================================
cat("  Original estimate:", round(theta_hat, 4), "\n")
#>   Original estimate: 11.2174
cat("  Jackknife mean:", round(theta_bar, 4), "\n")
#>   Jackknife mean: 11.2174
cat("  Jackknife SE:", round(se_jack, 4), "\n")
#>   Jackknife SE: 1.5468
cat("  Jackknife bias:", round(bias_jack, 4), "\n")
#>   Jackknife bias: 0
cat("  Bias-corrected estimate:", round(theta_jack, 4), "\n")
#>   Bias-corrected estimate: 11.2174

# Visualise leave-one-out estimates
jack_data <- data.table(
    index = 1:n,
    estimate = theta_loo
)

ggplot2$ggplot(jack_data, ggplot2$aes(x = index, y = estimate)) +
    ggplot2$geom_point(colour = "#2166AC", alpha = 0.6) +
    ggplot2$geom_hline(yintercept = theta_hat, linetype = "solid",
                        colour = "red", linewidth = 1) +
    ggplot2$geom_hline(yintercept = theta_bar, linetype = "dashed",
                        colour = "#D95F02", linewidth = 1) +
    ggplot2$annotate("text", x = n * 0.8, y = theta_hat + 0.5,
                      label = "Original estimate", colour = "red") +
    ggplot2$annotate("text", x = n * 0.8, y = theta_bar - 0.5,
                      label = "Jackknife mean", colour = "#D95F02") +
    ggplot2$labs(
        title = "Jackknife Leave-One-Out Estimates",
        subtitle = "Each point is the estimate with one observation removed",
        x = "Observation Removed",
        y = "Variance Estimate"
    ) +
    ggplot2$theme_minimal(base_size = 14) +
    ggplot2$theme(plot.title = ggplot2$element_text(face = "bold"))
```

<Figure src="jackknife_basics-1.png" alt="Jackknife leave-one-out estimates">
	Jackknife leave-one-out estimates
</Figure>

### 6.9.2 Jackknife Pseudo-Values and Influence

**Prose and Intuition**

The **pseudo-values** measure each observation's contribution to the estimate:

$$\tilde{\theta}_i = n\hat{\theta} - (n-1)\hat{\theta}_{(-i)}$$

If $\tilde{\theta}_i$ differs greatly from $\hat{\theta}$, observation $i$ is **influential**.

The pseudo-values are approximately independent with mean $\theta$ and variance $n \cdot Var(\hat{\theta})$. This allows using standard methods (t-tests, regression) on pseudo-values.













