---
title: "Algorithmic Trading with R"
chapter: "Chapter 2: Risk and Performance Metrics"
part: "Part 3: Risk-Adjusted Performance"
section: "02-3"
coverImage: 13
author: "Dereck Mezquita"
date: 2026-01-21
tags: [algorithmic-trading, quantitative-finance, R, statistics, sharpe-ratio, alpha, beta]
published: true
comments: true
output:
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
# HTML5 figure hook for accessibility
if (knitr::is_html_output()) knitr::knit_hooks$set(
    plot = function(x, options) {
        cap  <- options$fig.cap
        as.character(htmltools::tag(
            "Figure", list(src = x, alt = cap, paste("\n\t", cap, "\n", sep = ""))
        ))
    }
)

knitr::knit_hooks$set(optipng = knitr::hook_optipng)
knitr::opts_chunk$set(
    dpi = 300,
    fig.width = 10,
    fig.height = 7,
    comment = "",
    warning = FALSE,
    collapse = FALSE,
    results = 'hold'
)

options(box.path = getwd())
```

# Part 3: Risk-Adjusted Performance

Raw returns mean nothing without context. A strategy returning 20% annually sounds impressive until you learn it did so with 50% volatility and 60% drawdowns. Risk-adjusted metrics—Sharpe ratio, Sortino ratio, Information ratio, alpha—provide the context that separates genuine skill from leveraged luck.

This chapter covers the metrics that matter: how to calculate them, their statistical properties, and when each is appropriate.

```{r load-modules, message=FALSE}
box::use(
    ../modules/data[load_market, load_factors, filter_dates],
    ../modules/stats[sharpe_ratio, annualised_return, annualised_vol, max_drawdown],
    ../modules/viz[theme_trading, trading_colors]
)

box::use(
    data.table[...],
    ggplot2[...]
)

# Helper: convert trading_colors list to vector for indexed access
tc <- unlist(trading_colors)

set.seed(42)

# Load data
spy <- load_market("SPY")
spy <- spy[date >= "2000-01-01"]
spy[, returns := c(NA, diff(log(adjusted)))]
spy <- spy[!is.na(returns)]

# Load risk-free rate from Fama-French factors
ff_factors <- load_factors("ff3", "daily")
ff_factors <- ff_factors[date >= "2000-01-01"]
```

---

## 2.8 Sharpe Ratio

The Sharpe ratio is the universal language of quantitative finance. It measures return per unit of risk and enables comparison across strategies, asset classes, and time periods.

### 2.8.1 Prose/Intuition

William Sharpe introduced his ratio in 1966 as a way to evaluate mutual fund performance. The intuition is simple: how much excess return do you earn per unit of volatility?

$$\text{Sharpe Ratio} = \frac{\text{Excess Return}}{\text{Volatility}} = \frac{\mu - r_f}{\sigma}$$

A Sharpe ratio of 1.0 means you earn 1% excess return for each 1% of volatility. The ratio enables comparison because it's scale-independent: a strategy with 10% return and 10% volatility has the same Sharpe (1.0) as one with 30% return and 30% volatility.

**Industry benchmarks:**

| Sharpe | Interpretation |
|--------|---------------|
| < 0 | Losing money |
| 0-0.5 | Below average |
| 0.5-1.0 | Decent |
| 1.0-2.0 | Good |
| 2.0-3.0 | Excellent |
| > 3.0 | Suspicious (check your backtest) |

Sustained Sharpe ratios above 2.0 are rare outside of high-frequency trading. The S&P 500's long-term Sharpe is around 0.4-0.5. Most hedge funds deliver Sharpe ratios between 0.5 and 1.5.

**Important cautions:**

1. **Sharpe is estimated with uncertainty.** A 3-year backtest with Sharpe 1.5 has a 95% CI spanning roughly 0.5-2.5.

2. **Sharpe doesn't capture tail risk.** A strategy with negatively skewed returns (frequent small gains, occasional large losses) can have a high Sharpe while being extremely dangerous.

3. **Sharpe depends on frequency.** Daily Sharpe is not the same as monthly Sharpe (though they should be close if returns are i.i.d.).

### 2.8.2 Visual Evidence

```{r sharpe-iso, fig.cap="Iso-Sharpe lines in mean-volatility space. Each line represents constant Sharpe ratio; higher is better."}
# Create iso-Sharpe plot
vol_range <- seq(0.05, 0.40, by = 0.01)
sharpe_levels <- c(0.5, 1.0, 1.5, 2.0)

iso_sharpe <- rbindlist(lapply(sharpe_levels, function(sr) {
    data.table(
        volatility = vol_range,
        expected_return = sr * vol_range,  # Assuming rf = 0 for simplicity
        sharpe = sr
    )
}))
iso_sharpe[, sharpe_label := paste0("SR = ", sharpe)]

# Plot
ggplot(iso_sharpe, aes(x = volatility * 100, y = expected_return * 100,
                       colour = sharpe_label)) +
    geom_line(linewidth = 1) +
    scale_colour_manual(values = tc[1:4]) +
    # Add a point for S&P 500
    annotate("point", x = sd(spy$returns) * sqrt(252) * 100,
             y = mean(spy$returns) * 252 * 100, size = 4, colour = "black") +
    annotate("text", x = sd(spy$returns) * sqrt(252) * 100 + 2,
             y = mean(spy$returns) * 252 * 100,
             label = "S&P 500", hjust = 0) +
    labs(
        title = "Iso-Sharpe Lines: Return vs Volatility",
        subtitle = "Higher Sharpe means more return per unit risk",
        x = "Annualised Volatility (%)",
        y = "Annualised Excess Return (%)",
        colour = NULL
    ) +
    theme_trading() +
    theme(legend.position = "bottom") +
    coord_cartesian(xlim = c(5, 40), ylim = c(0, 60))
```

```{r sharpe-uncertainty, fig.cap="Distribution of estimated Sharpe ratios under sampling uncertainty. The true Sharpe of 1.0 generates widely varying estimates."}
# Simulate Sharpe ratio estimation uncertainty
# True Sharpe = 1.0, daily returns, 3 years of data
true_sharpe <- 1.0
n_days <- 3 * 252
n_sims <- 5000

# Generate simulations
set.seed(789)
simulated_sharpes <- replicate(n_sims, {
    daily_mu <- true_sharpe * 0.15 / sqrt(252)  # Assuming 15% annual vol
    daily_sigma <- 0.15 / sqrt(252)
    sim_returns <- rnorm(n_days, mean = daily_mu, sd = daily_sigma)

    ann_ret <- mean(sim_returns) * 252
    ann_vol <- sd(sim_returns) * sqrt(252)
    ann_ret / ann_vol
})

# Plot distribution
sim_dt <- data.table(sharpe = simulated_sharpes)

ggplot(sim_dt, aes(x = sharpe)) +
    geom_histogram(bins = 50, fill = tc[1], alpha = 0.8) +
    geom_vline(xintercept = true_sharpe, colour = tc[2],
               linewidth = 1.2, linetype = "dashed") +
    geom_vline(xintercept = quantile(simulated_sharpes, c(0.025, 0.975)),
               colour = tc[3], linewidth = 1, linetype = "dotted") +
    annotate("text", x = true_sharpe + 0.1, y = 350,
             label = "True Sharpe = 1.0", colour = tc[2], hjust = 0) +
    annotate("text", x = quantile(simulated_sharpes, 0.975) + 0.1, y = 300,
             label = "95% CI", colour = tc[3], hjust = 0) +
    labs(
        title = "Estimation Uncertainty in Sharpe Ratio",
        subtitle = sprintf("3 years of daily data: 95%% CI = [%.2f, %.2f]",
                          quantile(simulated_sharpes, 0.025),
                          quantile(simulated_sharpes, 0.975)),
        x = "Estimated Sharpe Ratio",
        y = "Frequency"
    ) +
    theme_trading()
```

### 2.8.3 Mathematical Derivation

**Definition:**

The Sharpe ratio is defined as:

$$\text{SR} = \frac{E[r] - r_f}{\sigma(r)} = \frac{\mu - r_f}{\sigma}$$

where $\mu$ is the expected return, $r_f$ is the risk-free rate, and $\sigma$ is the standard deviation of returns.

**Sample Sharpe ratio:**

$$\widehat{\text{SR}} = \frac{\hat{\mu} - r_f}{\hat{\sigma}} = \frac{\bar{r} - r_f}{s}$$

where $\bar{r}$ is the sample mean and $s$ is the sample standard deviation.

**Annualisation:**

For daily returns with annualisation factor $\sqrt{252}$:

$$\text{SR}_{\text{annual}} = \text{SR}_{\text{daily}} \times \sqrt{252}$$

**Derivation:**

If daily excess returns are i.i.d. with mean $\mu_d$ and variance $\sigma^2_d$, then annual returns (sum of 252 daily returns) have:
- Mean: $\mu_a = 252 \mu_d$
- Variance: $\sigma^2_a = 252 \sigma^2_d$
- Standard deviation: $\sigma_a = \sqrt{252} \sigma_d$

Therefore:
$$\text{SR}_a = \frac{\mu_a}{\sigma_a} = \frac{252\mu_d}{\sqrt{252}\sigma_d} = \sqrt{252} \cdot \frac{\mu_d}{\sigma_d} = \sqrt{252} \cdot \text{SR}_d$$

**Standard error of Sharpe ratio (Lo's formula):**

Andrew Lo (2002) derived the standard error of the sample Sharpe ratio:

$$SE(\widehat{\text{SR}}) \approx \sqrt{\frac{1 + \frac{\text{SR}^2}{2}}{T}}$$

For annual Sharpe ratios with $T$ years of data.

**Full derivation:**

The sample Sharpe ratio is a ratio of two random variables. Using the delta method:

$$\text{Var}\left(\frac{\hat{\mu}}{\hat{\sigma}}\right) \approx \frac{1}{\sigma^2}\text{Var}(\hat{\mu}) + \frac{\mu^2}{\sigma^4}\text{Var}(\hat{\sigma}) - \frac{2\mu}{\sigma^3}\text{Cov}(\hat{\mu}, \hat{\sigma})$$

Under normality:
- $\text{Var}(\hat{\mu}) = \sigma^2/T$
- $\text{Var}(\hat{\sigma}) \approx \sigma^2/(2T)$
- $\text{Cov}(\hat{\mu}, \hat{\sigma}) = 0$ (sample mean and variance are independent for normal data)

Substituting and simplifying:
$$\text{Var}(\widehat{\text{SR}}) \approx \frac{1}{T} + \frac{\mu^2}{2T\sigma^2} = \frac{1}{T}\left(1 + \frac{\text{SR}^2}{2}\right)$$

Taking square root gives Lo's formula.

**Confidence interval:**

A 95% confidence interval for the true Sharpe ratio is:
$$\widehat{\text{SR}} \pm 1.96 \cdot SE(\widehat{\text{SR}})$$

### 2.8.4 Implementation & Application

```{r sharpe-functions}
# Comprehensive Sharpe ratio calculation
calculate_sharpe <- function(returns, rf = 0, annualise = TRUE,
                             periods_per_year = 252) {
    returns <- returns[!is.na(returns)]
    T <- length(returns)

    # Calculate sample statistics
    mu <- mean(returns)
    sigma <- sd(returns)

    # Sharpe ratio
    sharpe_raw <- (mu - rf / periods_per_year) / sigma

    # Annualise
    if (annualise) {
        sharpe <- sharpe_raw * sqrt(periods_per_year)
        T_years <- T / periods_per_year
    } else {
        sharpe <- sharpe_raw
        T_years <- T
    }

    # Standard error (Lo's formula)
    se <- sqrt((1 + sharpe^2 / 2) / T_years)

    # Confidence interval
    ci_lower <- sharpe - 1.96 * se
    ci_upper <- sharpe + 1.96 * se

    # t-statistic for testing SR = 0
    t_stat <- sharpe / se
    p_value <- 2 * (1 - pnorm(abs(t_stat)))

    list(
        sharpe = sharpe,
        se = se,
        ci_lower = ci_lower,
        ci_upper = ci_upper,
        t_statistic = t_stat,
        p_value = p_value,
        n_periods = T,
        n_years = T_years
    )
}

# Calculate for S&P 500
spy_sharpe <- calculate_sharpe(spy$returns)

cat("S&P 500 Sharpe Ratio Analysis:\n")
cat(sprintf("  Sharpe ratio: %.2f\n", spy_sharpe$sharpe))
cat(sprintf("  Standard error: %.2f\n", spy_sharpe$se))
cat(sprintf("  95%% CI: [%.2f, %.2f]\n", spy_sharpe$ci_lower, spy_sharpe$ci_upper))
cat(sprintf("  t-statistic: %.2f (p = %.4f)\n", spy_sharpe$t_statistic, spy_sharpe$p_value))
cat(sprintf("  Based on %.1f years of data\n", spy_sharpe$n_years))
```

**Comparing strategy Sharpe ratios:**

Are two Sharpe ratios significantly different? We can use Lo's formula for the difference.

```{r sharpe-comparison}
# Function to compare two Sharpe ratios
compare_sharpe <- function(sharpe1, se1, sharpe2, se2) {
    # Assuming independence, the difference has SE = sqrt(SE1^2 + SE2^2)
    diff <- sharpe1 - sharpe2
    se_diff <- sqrt(se1^2 + se2^2)

    z_stat <- diff / se_diff
    p_value <- 2 * (1 - pnorm(abs(z_stat)))

    list(
        difference = diff,
        se = se_diff,
        z_statistic = z_stat,
        p_value = p_value
    )
}

# Example: Compare two periods of S&P 500
spy_early <- spy[date < "2010-01-01"]
spy_late <- spy[date >= "2010-01-01"]

sharpe_early <- calculate_sharpe(spy_early$returns)
sharpe_late <- calculate_sharpe(spy_late$returns)

comparison <- compare_sharpe(
    sharpe_early$sharpe, sharpe_early$se,
    sharpe_late$sharpe, sharpe_late$se
)

cat("\nSharpe Ratio Comparison (2000-2009 vs 2010+):\n")
cat(sprintf("  Period 1 (2000-2009): %.2f ± %.2f\n",
            sharpe_early$sharpe, sharpe_early$se * 1.96))
cat(sprintf("  Period 2 (2010+): %.2f ± %.2f\n",
            sharpe_late$sharpe, sharpe_late$se * 1.96))
cat(sprintf("  Difference: %.2f ± %.2f\n",
            comparison$difference, comparison$se * 1.96))
cat(sprintf("  z-statistic: %.2f (p = %.4f)\n",
            comparison$z_statistic, comparison$p_value))
```

---

## 2.9 Sortino and Calmar Ratios

The Sharpe ratio penalises upside and downside volatility equally. Sortino and Calmar ratios focus specifically on downside risk.

### 2.9.1 Prose/Intuition

**Sortino ratio:**

Investors don't mind upside volatility—that's "good" risk. The Sortino ratio replaces total volatility with downside deviation:

$$\text{Sortino} = \frac{\mu - r_f}{\sigma_{\text{downside}}}$$

A strategy with positive skew (frequent small losses, occasional large gains) will have a Sortino ratio higher than its Sharpe ratio. A negatively skewed strategy (frequent small gains, occasional large losses) will have Sortino lower than Sharpe.

**Calmar ratio:**

The Calmar ratio (named after California Managed Accounts Report) measures return relative to maximum drawdown:

$$\text{Calmar} = \frac{\text{CAGR}}{\text{Max Drawdown}}$$

This is popular for evaluating CTAs and managed futures because it directly relates return to the worst historical pain. A Calmar of 1.0 means your annual return equals your worst drawdown.

**When to use each:**

| Metric | Use when... |
|--------|------------|
| Sharpe | Default comparison; symmetric returns |
| Sortino | Asymmetric returns; care about downside |
| Calmar | Maximum loss tolerance matters; CTA evaluation |

### 2.9.2 Visual Evidence

```{r sortino-vs-sharpe, fig.cap="Strategies with identical Sharpe but different Sortino ratios, reflecting different return asymmetries."}
set.seed(321)
n <- 1000

# Strategy A: Symmetric returns (Sharpe ≈ Sortino)
returns_symmetric <- rnorm(n, mean = 0.0004, sd = 0.01)

# Strategy B: Positive skew (Sortino > Sharpe)
# Frequent small losses, occasional large gains
returns_pos_skew <- c(
    rnorm(700, mean = -0.001, sd = 0.005),  # Small losses
    rnorm(300, mean = 0.005, sd = 0.012)    # Larger gains
)
returns_pos_skew <- sample(returns_pos_skew)
# Scale to similar mean as symmetric
returns_pos_skew <- returns_pos_skew - mean(returns_pos_skew) + mean(returns_symmetric)

# Strategy C: Negative skew (Sortino < Sharpe)
# Frequent small gains, occasional large losses
returns_neg_skew <- c(
    rnorm(700, mean = 0.002, sd = 0.004),   # Small gains
    rnorm(300, mean = -0.008, sd = 0.015)   # Larger losses
)
returns_neg_skew <- sample(returns_neg_skew)
returns_neg_skew <- returns_neg_skew - mean(returns_neg_skew) + mean(returns_symmetric)

# Calculate metrics
calculate_sortino <- function(returns, rf = 0, periods_per_year = 252) {
    excess <- returns - rf / periods_per_year
    down_dev <- sqrt(mean(pmin(excess, 0)^2)) * sqrt(periods_per_year)
    ann_ret <- mean(excess) * periods_per_year
    ann_ret / down_dev
}

metrics <- data.table(
    Strategy = c("Symmetric", "Positive Skew", "Negative Skew"),
    Sharpe = c(
        mean(returns_symmetric) / sd(returns_symmetric) * sqrt(252),
        mean(returns_pos_skew) / sd(returns_pos_skew) * sqrt(252),
        mean(returns_neg_skew) / sd(returns_neg_skew) * sqrt(252)
    ),
    Sortino = c(
        calculate_sortino(returns_symmetric),
        calculate_sortino(returns_pos_skew),
        calculate_sortino(returns_neg_skew)
    ),
    Skewness = c(
        moments::skewness(returns_symmetric),
        moments::skewness(returns_pos_skew),
        moments::skewness(returns_neg_skew)
    )
)

# Plot return distributions
dist_dt <- rbindlist(list(
    data.table(Strategy = "Symmetric", returns = returns_symmetric * 100),
    data.table(Strategy = "Positive Skew", returns = returns_pos_skew * 100),
    data.table(Strategy = "Negative Skew", returns = returns_neg_skew * 100)
))

# Add metric labels
dist_dt[, Strategy := factor(Strategy, levels = c("Symmetric", "Positive Skew", "Negative Skew"))]

ggplot(dist_dt, aes(x = returns, fill = Strategy)) +
    geom_histogram(bins = 50, alpha = 0.7) +
    geom_vline(xintercept = 0, linetype = "dashed", colour = "grey50") +
    facet_wrap(~Strategy, ncol = 1, scales = "free_y") +
    scale_fill_manual(values = tc[1:3]) +
    labs(
        title = "Return Distributions: Different Skewness Profiles",
        subtitle = "Similar Sharpe, different Sortino",
        x = "Daily Return (%)",
        y = "Frequency"
    ) +
    theme_trading() +
    theme(legend.position = "none")

# Print metrics table
cat("\nMetrics Comparison:\n")
print(metrics[, .(Strategy,
                  Sharpe = round(Sharpe, 2),
                  Sortino = round(Sortino, 2),
                  `Sortino/Sharpe` = round(Sortino/Sharpe, 2),
                  Skewness = round(Skewness, 2))])
```

```{r calmar-analysis, fig.cap="Calmar ratio decomposition showing the trade-off between returns and maximum drawdown."}
# Calculate Calmar for S&P 500 over rolling windows
# Use 3-year rolling windows
window <- 3 * 252

spy[, roll_cagr := frollapply(returns, window, function(x) {
    prod(1 + x)^(252 / length(x)) - 1
})]

# Rolling max drawdown
spy[, roll_mdd := frollapply(returns, window, function(x) {
    wealth <- cumprod(1 + x)
    hwm <- cummax(wealth)
    max(1 - wealth / hwm)
})]

spy[, roll_calmar := roll_cagr / roll_mdd]

# Plot Calmar over time
spy_calmar <- spy[!is.na(roll_calmar) & is.finite(roll_calmar)]

ggplot(spy_calmar, aes(x = date, y = roll_calmar)) +
    geom_line(colour = tc[1], linewidth = 0.7) +
    geom_hline(yintercept = c(0.5, 1.0), linetype = "dashed", colour = "grey50") +
    annotate("text", x = as.Date("2005-01-01"), y = 1.1,
             label = "Calmar = 1.0", colour = "grey50", size = 3) +
    labs(
        title = "Rolling 3-Year Calmar Ratio: S&P 500",
        subtitle = "Calmar captures return per unit of maximum pain",
        x = NULL,
        y = "Calmar Ratio"
    ) +
    theme_trading() +
    coord_cartesian(ylim = c(-1, 2))
```

### 2.9.3 Mathematical Derivation

**Sortino ratio:**

$$\text{Sortino} = \frac{E[r] - r_f}{\sigma_{\text{down}}}$$

where the downside deviation is:

$$\sigma_{\text{down}} = \sqrt{E[\min(r - \tau, 0)^2]}$$

The target $\tau$ is typically 0 or $r_f$.

**Sample Sortino:**

$$\widehat{\text{Sortino}} = \frac{\bar{r} - r_f}{\sqrt{\frac{1}{T}\sum_{t: r_t < \tau} (r_t - \tau)^2}}$$

**Relationship to Sharpe:**

For symmetric distributions: $\sigma_{\text{down}} \approx \sigma/\sqrt{2}$, so:
$$\text{Sortino} \approx \sqrt{2} \times \text{Sharpe}$$

For positively skewed distributions: $\sigma_{\text{down}} < \sigma/\sqrt{2}$, so Sortino > Sharpe × √2.
For negatively skewed distributions: $\sigma_{\text{down}} > \sigma/\sqrt{2}$, so Sortino < Sharpe × √2.

**Calmar ratio:**

$$\text{Calmar} = \frac{\text{CAGR}}{\text{MDD}}$$

where:
- $\text{CAGR} = (W_T/W_0)^{1/T} - 1$ is the compound annual growth rate
- $\text{MDD} = \max_t (1 - W_t/\text{HWM}_t)$ is the maximum drawdown

**Annualisation:**

For Sortino with daily data:
$$\text{Sortino}_{\text{annual}} = \text{Sortino}_{\text{daily}} \times \sqrt{252}$$

Calmar is already expressed in annual terms.

### 2.9.4 Implementation & Application

```{r sortino-calmar-functions}
# Sortino ratio
sortino_ratio <- function(returns, rf = 0, target = 0, annualise = TRUE,
                          periods_per_year = 252) {
    returns <- returns[!is.na(returns)]

    excess <- returns - rf / periods_per_year
    mu <- mean(excess)

    # Downside deviation relative to target
    downside <- returns - target / periods_per_year
    downside_sq <- pmin(downside, 0)^2
    down_dev <- sqrt(mean(downside_sq))

    if (annualise) {
        ann_return <- mu * periods_per_year
        ann_down_dev <- down_dev * sqrt(periods_per_year)
    } else {
        ann_return <- mu
        ann_down_dev <- down_dev
    }

    ann_return / ann_down_dev
}

# Calmar ratio
calmar_ratio <- function(returns, periods_per_year = 252) {
    returns <- returns[!is.na(returns)]
    T <- length(returns)

    # CAGR
    total_return <- prod(1 + returns)
    years <- T / periods_per_year
    cagr <- total_return^(1/years) - 1

    # Maximum drawdown
    wealth <- cumprod(1 + returns)
    hwm <- cummax(wealth)
    mdd <- max(1 - wealth / hwm)

    cagr / mdd
}

# Calculate for S&P 500
spy_sortino <- sortino_ratio(spy$returns)
spy_calmar <- calmar_ratio(spy$returns)

cat("S&P 500 Risk-Adjusted Metrics:\n")
cat(sprintf("  Sharpe ratio: %.2f\n", spy_sharpe$sharpe))
cat(sprintf("  Sortino ratio: %.2f\n", spy_sortino))
cat(sprintf("  Sortino/Sharpe ratio: %.2f\n", spy_sortino / spy_sharpe$sharpe))
cat(sprintf("  Calmar ratio: %.2f\n", spy_calmar))
```

---

## 2.10 Information Ratio and Tracking Error

When managing against a benchmark, the relevant question is not absolute return but **active return**: how much did you beat (or trail) the benchmark?

### 2.10.1 Prose/Intuition

The Information Ratio (IR) is the Sharpe ratio of active returns:

$$\text{IR} = \frac{E[r_p - r_b]}{\sigma(r_p - r_b)} = \frac{\text{Active Return}}{\text{Tracking Error}}$$

where:
- $r_p$ is portfolio return
- $r_b$ is benchmark return
- Tracking Error (TE) is the volatility of the difference

The IR measures active management skill, separating benchmark exposure from genuine alpha generation. An IR of 0.5 is considered good for active managers; 1.0 is excellent.

**Why IR matters:**

Suppose a fund returns 12% when the benchmark returns 10%. Is the manager skilled, or just taking more risk? If the fund has beta = 1.5 to the benchmark, the expected return is roughly $1.5 \times 10\% = 15\%$, meaning the manager actually underperformed on a risk-adjusted basis.

The IR strips out benchmark exposure and measures pure stock-picking (or factor-timing) skill.

### 2.10.2 Visual Evidence

```{r tracking-error, fig.cap="Active returns (portfolio minus benchmark) over time. Tracking error measures the volatility of this series."}
# Simulate an active strategy
# Use S&P 500 as benchmark
set.seed(456)

# Generate portfolio returns: benchmark + alpha + noise
alpha <- 0.0002  # 5 bps daily alpha
tracking_vol <- 0.005  # 5% tracking error (annualised ~8%)
active_noise <- rnorm(nrow(spy), mean = 0, sd = tracking_vol)

spy[, portfolio_returns := returns + alpha + active_noise]
spy[, active_returns := portfolio_returns - returns]

# Plot active returns
ggplot(spy, aes(x = date, y = active_returns * 100)) +
    geom_line(colour = tc[1], linewidth = 0.3) +
    geom_hline(yintercept = 0, linetype = "dashed", colour = "grey50") +
    labs(
        title = "Active Returns: Portfolio Minus Benchmark",
        subtitle = "Tracking error is the volatility of this series",
        x = NULL,
        y = "Active Return (%)"
    ) +
    theme_trading()
```

```{r ir-distribution, fig.cap="Distribution of active returns showing positive mean (alpha) and tracking error (standard deviation)."}
# Plot distribution of active returns
ggplot(spy, aes(x = active_returns * 100)) +
    geom_histogram(bins = 50, fill = tc[1], alpha = 0.8) +
    geom_vline(xintercept = mean(spy$active_returns) * 100,
               colour = tc[2], linewidth = 1.2) +
    geom_vline(xintercept = 0, linetype = "dashed", colour = "grey50") +
    annotate("text", x = mean(spy$active_returns) * 100 + 0.1, y = 400,
             label = sprintf("Mean active return:\n%.3f%% daily",
                            mean(spy$active_returns) * 100),
             colour = tc[2], hjust = 0, size = 3.5) +
    labs(
        title = "Distribution of Active Returns",
        subtitle = sprintf("Tracking Error: %.2f%% annualised",
                          sd(spy$active_returns) * sqrt(252) * 100),
        x = "Daily Active Return (%)",
        y = "Frequency"
    ) +
    theme_trading()
```

### 2.10.3 Mathematical Derivation

**Definitions:**

- **Active return**: $r_{\text{active}} = r_p - r_b$
- **Tracking error**: $\text{TE} = \sigma(r_{\text{active}}) = \sqrt{\text{Var}(r_p - r_b)}$
- **Information ratio**: $\text{IR} = \frac{E[r_{\text{active}}]}{\text{TE}}$

**Relationship to Sharpe:**

The IR is the Sharpe ratio of active returns:
$$\text{IR} = \text{Sharpe}(r_{\text{active}})$$

**Tracking error decomposition:**

$$\text{TE}^2 = \text{Var}(r_p - r_b) = \text{Var}(r_p) + \text{Var}(r_b) - 2\text{Cov}(r_p, r_b)$$

For a portfolio with beta $\beta$ to the benchmark:
$$r_p = \alpha + \beta r_b + \epsilon$$

The tracking error is:
$$\text{TE}^2 = (1 - \beta)^2 \sigma^2_b + \sigma^2_\epsilon$$

For $\beta = 1$ (benchmark-neutral): $\text{TE} = \sigma_\epsilon$ (pure stock-picking volatility).

**IR vs Sharpe:**

The relationship between portfolio Sharpe and IR depends on benchmark correlation:
$$\text{SR}_p = \rho \cdot \text{SR}_b + \sqrt{1 - \rho^2} \cdot \text{IR}$$

where $\rho$ is the correlation between portfolio and benchmark returns.

### 2.10.4 Implementation & Application

```{r ir-functions}
# Information ratio calculation
information_ratio <- function(portfolio_returns, benchmark_returns,
                              annualise = TRUE, periods_per_year = 252) {
    # Align and clean
    active <- portfolio_returns - benchmark_returns
    active <- active[!is.na(active)]

    # Active return and tracking error
    active_mean <- mean(active)
    tracking_error <- sd(active)

    if (annualise) {
        active_mean <- active_mean * periods_per_year
        tracking_error <- tracking_error * sqrt(periods_per_year)
    }

    ir <- active_mean / tracking_error

    list(
        information_ratio = ir,
        active_return = active_mean,
        tracking_error = tracking_error,
        n_periods = length(active)
    )
}

# Calculate for our simulated portfolio
ir_result <- information_ratio(spy$portfolio_returns, spy$returns)

cat("Simulated Active Portfolio:\n")
cat(sprintf("  Information ratio: %.2f\n", ir_result$information_ratio))
cat(sprintf("  Active return: %.2f%% annualised\n", ir_result$active_return * 100))
cat(sprintf("  Tracking error: %.2f%% annualised\n", ir_result$tracking_error * 100))

# Compare to portfolio Sharpe
portfolio_sharpe <- calculate_sharpe(spy$portfolio_returns)
benchmark_sharpe <- calculate_sharpe(spy$returns)

cat(sprintf("\n  Portfolio Sharpe: %.2f\n", portfolio_sharpe$sharpe))
cat(sprintf("  Benchmark Sharpe: %.2f\n", benchmark_sharpe$sharpe))
```

**IR targets for institutional managers:**

```{r ir-targets}
# Illustrate what different IR values mean
ir_values <- c(0.25, 0.50, 0.75, 1.00)
te_values <- c(0.02, 0.04, 0.06, 0.08)  # 2%, 4%, 6%, 8% tracking error

ir_grid <- CJ(IR = ir_values, TE = te_values)
ir_grid[, Active_Return := IR * TE]

cat("\nActive Return Matrix (IR × TE):\n")
cat("            TE = 2%   TE = 4%   TE = 6%   TE = 8%\n")
for (ir in ir_values) {
    row <- ir_grid[IR == ir, sprintf("%.1f%%", Active_Return * 100)]
    cat(sprintf("IR = %.2f   %s   %s   %s   %s\n", ir, row[1], row[2], row[3], row[4]))
}
```

---

## 2.11 Alpha and Beta

Alpha and beta decompose returns into market exposure and residual skill. Beta measures sensitivity to a benchmark; alpha measures return beyond what beta would predict.

### 2.11.1 Prose/Intuition

The Capital Asset Pricing Model (CAPM) says expected returns should be proportional to market risk:

$$E[r_p] - r_f = \beta (E[r_m] - r_f)$$

If a portfolio has $\beta = 1.5$, it should earn 1.5× the market risk premium. Any return beyond this is **alpha**—unexplained outperformance that presumably reflects skill.

The market model regression:
$$r_p - r_f = \alpha + \beta (r_m - r_f) + \epsilon$$

- $\beta$ measures how much the portfolio moves with the market
- $\alpha$ is the intercept—average return unexplained by market exposure
- $\epsilon$ is idiosyncratic noise

**Interpretation:**

- $\beta > 1$: More volatile than market, amplifies moves
- $\beta < 1$: Less volatile, dampens moves
- $\beta = 0$: Market-neutral
- $\alpha > 0$: Outperforms after adjusting for beta
- $\alpha < 0$: Underperforms after adjusting for beta

**Caution:** Alpha can be illusory if there are hidden factor exposures (e.g., a fund might have low market beta but high exposure to size or value factors).

### 2.11.2 Visual Evidence

```{r alpha-beta-scatter, fig.cap="Scatter plot of portfolio vs benchmark returns. The slope is beta; the intercept is alpha."}
# Create portfolio with known beta and alpha
set.seed(789)

# Simulate portfolio: beta = 1.2, alpha = 3% annual
true_beta <- 1.2
true_alpha <- 0.03 / 252  # Daily alpha

spy[, sim_portfolio := true_alpha + true_beta * returns + rnorm(.N, 0, 0.005)]

# Scatter plot
ggplot(spy, aes(x = returns * 100, y = sim_portfolio * 100)) +
    geom_point(alpha = 0.2, size = 1, colour = tc[1]) +
    geom_smooth(method = "lm", colour = tc[2], linewidth = 1.2) +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", colour = "grey50") +
    annotate("text", x = 3, y = -2, label = "β = 1 line", colour = "grey50", size = 3) +
    labs(
        title = "Portfolio vs Benchmark Returns",
        subtitle = sprintf("Slope (β) = %.2f, Intercept (α) = %.4f%% daily",
                          coef(lm(sim_portfolio ~ returns, data = spy))[2],
                          coef(lm(sim_portfolio ~ returns, data = spy))[1] * 100),
        x = "Benchmark Return (%)",
        y = "Portfolio Return (%)"
    ) +
    theme_trading() +
    coord_fixed(ratio = 1, xlim = c(-10, 10), ylim = c(-10, 10))
```

```{r rolling-beta, fig.cap="Rolling 252-day beta of S&P 500 (SPY) vs itself is always 1.0. A leveraged fund would show beta > 1."}
# Calculate rolling beta for our simulated portfolio using a loop-based approach
roll_reg <- function(y, x, window = 252) {
    n <- length(y)
    beta <- rep(NA_real_, n)
    alpha <- rep(NA_real_, n)

    for (i in window:n) {
        idx <- (i - window + 1):i
        fit <- lm(y[idx] ~ x[idx])
        beta[i] <- coef(fit)[2]
        alpha[i] <- coef(fit)[1]
    }

    list(beta = beta, alpha = alpha)
}

reg_results <- roll_reg(spy$sim_portfolio, spy$returns)
spy[, roll_beta := reg_results$beta]
spy[, roll_alpha := reg_results$alpha]

# Plot rolling beta
ggplot(spy[!is.na(roll_beta)], aes(x = date, y = roll_beta)) +
    geom_line(colour = tc[1], linewidth = 0.7) +
    geom_hline(yintercept = true_beta, colour = tc[2],
               linetype = "dashed", linewidth = 1) +
    geom_hline(yintercept = 1, colour = "grey50", linetype = "dotted") +
    annotate("text", x = as.Date("2005-01-01"), y = true_beta + 0.05,
             label = sprintf("True β = %.1f", true_beta),
             colour = tc[2]) +
    labs(
        title = "Rolling 252-Day Beta",
        subtitle = "Beta fluctuates around the true value due to estimation error",
        x = NULL,
        y = "Beta"
    ) +
    theme_trading()
```

### 2.11.3 Mathematical Derivation

**Market model:**

$$r_p - r_f = \alpha + \beta (r_m - r_f) + \epsilon$$

where $E[\epsilon] = 0$ and $\text{Cov}(\epsilon, r_m) = 0$.

**Beta derivation (OLS):**

Beta is the slope coefficient from regressing excess portfolio returns on excess market returns:

$$\beta = \frac{\text{Cov}(r_p - r_f, r_m - r_f)}{\text{Var}(r_m - r_f)} = \frac{\text{Cov}(r_p, r_m)}{\text{Var}(r_m)}$$

**Derivation:**

Minimising the sum of squared residuals:
$$\min_{\alpha, \beta} \sum_{t=1}^T [(r_{p,t} - r_f) - \alpha - \beta(r_{m,t} - r_f)]^2$$

Taking partial derivatives and setting to zero:
$$\frac{\partial}{\partial \beta}: -2\sum(r_{m,t} - r_f)[(r_{p,t} - r_f) - \alpha - \beta(r_{m,t} - r_f)] = 0$$

Solving (using the normal equations):
$$\hat{\beta} = \frac{\sum(r_{m,t} - \bar{r}_m)(r_{p,t} - \bar{r}_p)}{\sum(r_{m,t} - \bar{r}_m)^2} = \frac{\widehat{\text{Cov}}(r_p, r_m)}{\widehat{\text{Var}}(r_m)}$$

**Alpha:**

$$\hat{\alpha} = (\bar{r}_p - r_f) - \hat{\beta}(\bar{r}_m - r_f)$$

**Standard errors:**

Under classical assumptions:
$$SE(\hat{\beta}) = \frac{\hat{\sigma}_\epsilon}{\sqrt{\sum(r_m - \bar{r}_m)^2}}$$

$$SE(\hat{\alpha}) = \hat{\sigma}_\epsilon \sqrt{\frac{1}{T} + \frac{\bar{r}_m^2}{\sum(r_m - \bar{r}_m)^2}}$$

where $\hat{\sigma}^2_\epsilon = \frac{1}{T-2}\sum\hat{\epsilon}^2_t$ is the residual variance.

**Hypothesis tests:**

- $H_0: \beta = 0$ vs $H_1: \beta \neq 0$ tests for market exposure
- $H_0: \alpha = 0$ vs $H_1: \alpha \neq 0$ tests for skill (after controlling for beta)

t-statistics: $t_\beta = \hat{\beta}/SE(\hat{\beta})$, $t_\alpha = \hat{\alpha}/SE(\hat{\alpha})$

### 2.11.4 Implementation & Application

```{r alpha-beta-functions}
# Comprehensive alpha-beta analysis
alpha_beta_analysis <- function(portfolio_returns, benchmark_returns, rf = 0,
                                 periods_per_year = 252) {
    # Clean and align
    n <- length(portfolio_returns)
    idx <- !is.na(portfolio_returns) & !is.na(benchmark_returns)

    y <- portfolio_returns[idx] - rf / periods_per_year  # Excess portfolio
    x <- benchmark_returns[idx] - rf / periods_per_year  # Excess benchmark

    # OLS regression
    fit <- lm(y ~ x)
    coeffs <- coef(fit)
    alpha <- coeffs[1]
    beta <- coeffs[2]

    # Standard errors and t-stats
    summ <- summary(fit)
    se_alpha <- summ$coefficients[1, 2]
    se_beta <- summ$coefficients[2, 2]
    t_alpha <- summ$coefficients[1, 3]
    t_beta <- summ$coefficients[2, 3]
    p_alpha <- summ$coefficients[1, 4]
    p_beta <- summ$coefficients[2, 4]

    # R-squared
    r_squared <- summ$r.squared

    # Annualise alpha
    alpha_annual <- alpha * periods_per_year
    se_alpha_annual <- se_alpha * periods_per_year

    # Residual volatility (tracking error after beta adjustment)
    residual_vol <- sd(residuals(fit)) * sqrt(periods_per_year)

    list(
        alpha_daily = alpha,
        alpha_annual = alpha_annual,
        se_alpha_annual = se_alpha_annual,
        t_alpha = t_alpha,
        p_alpha = p_alpha,
        beta = beta,
        se_beta = se_beta,
        t_beta = t_beta,
        p_beta = p_beta,
        r_squared = r_squared,
        residual_volatility = residual_vol,
        n_observations = sum(idx)
    )
}

# Analyse our simulated portfolio
ab_result <- alpha_beta_analysis(spy$sim_portfolio, spy$returns)

cat("Alpha-Beta Analysis:\n")
cat(sprintf("  Alpha: %.2f%% annualised (SE: %.2f%%)\n",
            ab_result$alpha_annual * 100, ab_result$se_alpha_annual * 100))
cat(sprintf("  t-statistic: %.2f (p = %.4f)\n", ab_result$t_alpha, ab_result$p_alpha))
cat(sprintf("\n  Beta: %.3f (SE: %.3f)\n", ab_result$beta, ab_result$se_beta))
cat(sprintf("  t-statistic: %.2f (p = %.4f)\n", ab_result$t_beta, ab_result$p_beta))
cat(sprintf("\n  R-squared: %.1f%%\n", ab_result$r_squared * 100))
cat(sprintf("  Residual volatility: %.2f%%\n", ab_result$residual_volatility * 100))

# Compare true vs estimated
cat(sprintf("\n  True alpha: %.2f%% | Estimated: %.2f%%\n",
            true_alpha * 252 * 100, ab_result$alpha_annual * 100))
cat(sprintf("  True beta: %.2f | Estimated: %.2f\n",
            true_beta, ab_result$beta))
```

**Detecting hidden beta exposures:**

```{r hidden-beta}
# Example: A "market neutral" fund with hidden factor exposures
# Load Fama-French factors
ff <- load_factors("ff3", "daily")
ff <- ff[date >= "2000-01-01"]

# Merge with SPY dates
analysis_dt <- merge(spy[, .(date, returns)], ff, by = "date")

# Simulate a factor portfolio: claims to be market neutral but has SMB/HML exposure
set.seed(111)
analysis_dt[, factor_portfolio :=
    0.00015 +  # 3.5% annual alpha
    0.1 * Mkt_RF +  # Low market beta
    0.5 * SMB +  # Hidden small cap exposure
    0.3 * HML +  # Hidden value exposure
    rnorm(.N, 0, 0.003)]

# Single-factor analysis (looks market neutral)
single_factor <- alpha_beta_analysis(
    analysis_dt$factor_portfolio,
    analysis_dt$Mkt_RF
)

# Multi-factor analysis (reveals hidden exposures)
multi_factor_fit <- lm(factor_portfolio ~ Mkt_RF + SMB + HML,
                       data = analysis_dt)

cat("\nHidden Factor Exposure Detection:\n")
cat("\nSingle-Factor Analysis (Market Only):\n")
cat(sprintf("  Alpha: %.2f%% (t = %.2f)\n",
            single_factor$alpha_annual * 100, single_factor$t_alpha))
cat(sprintf("  Market beta: %.2f\n", single_factor$beta))
cat(sprintf("  R-squared: %.1f%%\n", single_factor$r_squared * 100))

cat("\nMulti-Factor Analysis (Fama-French 3-Factor):\n")
multi_summ <- summary(multi_factor_fit)
cat(sprintf("  Alpha: %.2f%% (t = %.2f)\n",
            coef(multi_factor_fit)[1] * 252 * 100,
            multi_summ$coefficients[1, 3]))
cat(sprintf("  Market beta: %.2f\n", coef(multi_factor_fit)[2]))
cat(sprintf("  SMB beta: %.2f (t = %.2f)\n",
            coef(multi_factor_fit)[3], multi_summ$coefficients[3, 3]))
cat(sprintf("  HML beta: %.2f (t = %.2f)\n",
            coef(multi_factor_fit)[4], multi_summ$coefficients[4, 3]))
cat(sprintf("  R-squared: %.1f%%\n", multi_summ$r.squared * 100))
```

---

## Quick Reference: Risk-Adjusted Metrics

### Core Ratios

| Metric | Formula | Benchmark |
|--------|---------|-----------|
| Sharpe | $(E[r] - r_f) / \sigma$ | 1.0 = good, 2.0 = excellent |
| Sortino | $(E[r] - r_f) / \sigma_{\text{down}}$ | ≈ 1.4 × Sharpe if symmetric |
| Calmar | CAGR / MDD | 0.5-1.0 typical |
| Information | $E[r_p - r_b] / \text{TE}$ | 0.5 = good for active |

### Alpha and Beta

| Metric | Formula | Notes |
|--------|---------|-------|
| Beta | $\text{Cov}(r_p, r_m) / \text{Var}(r_m)$ | Market sensitivity |
| Alpha | $\bar{r}_p - r_f - \beta(\bar{r}_m - r_f)$ | Unexplained return |
| Tracking Error | $\sigma(r_p - r_b)$ | Active risk |

### Standard Errors

| Metric | SE Formula |
|--------|------------|
| Sharpe | $\sqrt{(1 + \text{SR}^2/2)/T}$ |
| Beta | $\sigma_\epsilon / \sqrt{\sum(r_m - \bar{r}_m)^2}$ |
| Alpha | Complex; use regression output |

### R Code Snippets

```r
# Sharpe ratio
sharpe <- (mean(returns) - rf) / sd(returns) * sqrt(252)

# Sortino ratio
downside <- returns[returns < 0]
sortino <- (mean(returns) - rf) * 252 / (sqrt(mean(downside^2)) * sqrt(252))

# Information ratio
active <- portfolio - benchmark
ir <- mean(active) * 252 / (sd(active) * sqrt(252))

# Alpha and beta
fit <- lm(portfolio ~ benchmark)
alpha <- coef(fit)[1] * 252  # Annualised
beta <- coef(fit)[2]

# Calmar ratio
cagr <- prod(1 + returns)^(252/length(returns)) - 1
mdd <- max(1 - cumprod(1+returns) / cummax(cumprod(1+returns)))
calmar <- cagr / mdd
```

### Interpretation Guidelines

1. **Sharpe ratio has wide confidence intervals.** A 5-year Sharpe of 1.5 has 95% CI roughly [0.6, 2.4].

2. **Sortino > √2 × Sharpe suggests positive skew.** This is desirable; you have asymmetric upside.

3. **Low beta doesn't mean low risk.** Hidden factor exposures can make "market neutral" funds risky.

4. **Alpha is meaningful only after controlling for all relevant factors.** Single-factor alpha often overstates skill.

5. **Use Information Ratio for benchmark-relative evaluation.** Sharpe measures absolute risk-adjusted return; IR measures active skill.
