---
title: "Introduction to Statistics with R: Reproducible Research and Communication of Results"
blurb: "Blue and white mean war"
coverImage: 13
author: "Dereck Mezquita"
date: 2023-10-20
tags: [statistics, mathematics, probability, data]
published: true
comments: true
output: 
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
# https://bookdown.org/yihui/rmarkdown-cookbook/hook-html5.html
if (knitr::is_html_output()) knitr::knit_hooks$set(
    plot = function(x, options) {
        cap  <- options$fig.cap
        # x <- paste0("/courses/", x)
        as.character(htmltools::tag(
            "Figure", list(src = x, alt = cap, paste("\n\t", cap, "\n", sep = ""))
        ))
    }
)

knitr::knit_hooks$set(optipng = knitr::hook_optipng) # optipng = '-o7'
knitr::opts_chunk$set(dpi = 300, fig.width = 10, fig.height = 7)
```

# Reproducible Research and Communication of Results

## Literate Programming and Dynamic Documents

Modern data science and statistical analysis benefit greatly from literate programming[^1], where code, narrative, and results coexist in a single document. This practice enhances reproducibility, transparency, and collaboration by bundling code, outputs, and prose together. Key tools in the R ecosystem for literate programming include **RMarkdown**, **Quarto**, and **knitr**, each enabling you to create dynamic, interactive documents that can be easily shared and updated.

### RMarkdown, Quarto, and knitr

**Conceptual Overview:**  
- **RMarkdown:** A file format (`.Rmd`) that merges code (R and other languages), markdown text, and output. When rendered, it produces outputs like HTML, PDF, or Word documents.  
- **Quarto:** A next-generation tool that extends beyond RMarkdown, supporting multiple languages (R, Python, Julia) and offering more publishing and formatting options.  
- **knitr:** The R package that underpins RMarkdown, facilitating the execution of code chunks and insertion of their results into documents.

These tools allow you to present statistical analysis as a coherent narrative: you can explain your methods, show your code, and present results (tables, figures) inline. This reduces the “copy-paste” cycle, making your workflow more efficient, transparent, and less error-prone.

**Key Advantages:**
- **Reproducibility:** If someone reruns your `.Rmd` or Quarto document, they get the same results, ensuring transparency and trust.
- **Version Control:** Storing `.Rmd` or Quarto source files in Git allows you to track changes in code, text, and data processing steps.
- **Communication:** By weaving code and outputs together, collaborators and stakeholders can follow the logic of the analysis, making complex methods more accessible.

### Parameterised Reports and Interactive Notebooks

**Parameterised Reports:**
- Parameterised reports allow you to define parameters (e.g., dataset name, date range, filtering criteria) at the start of your document.  
- When you “knit” or “render” the report, you can supply different values for these parameters without editing the code. This is useful if you need to produce the same analysis for multiple groups, time periods, or scenarios.

**Example:**
Let’s assume we have a parameter `region` that specifies which subset of data we want to analyse. In an RMarkdown file, you can define parameters in the YAML header:

\`\`\`
---
title: "Sales Report"
params:
  region: "Asia"
output: html_document
---
\`\`\`

Within the report, you can refer to `params$region` to filter data accordingly.

**Code Example (Assuming a CSV with sales data):**
Please note, if we need a real dataset, let me know and I can suggest one. For demonstration, let’s assume we have `sales_data.csv` with columns `Region`, `Product`, `Sales`. If we do not have such data, we can simulate it.

\`\`\{r echo=TRUE\}
# Simulate some sales data if we don't have a real dataset:
# This is for demonstration; in practice, you'd read a real dataset.
if(!requireNamespace("data.table", quietly=TRUE)) {
  install.packages("data.table")
}
library(data.table)

set.seed(123)
dt <- data.table(
  Region=sample(c("Asia","Europe","Americas"), 100, replace=TRUE),
  Product=sample(c("Gadget","Widget","Thingamajig"), 100, replace=TRUE),
  Sales=round(runif(100, 10, 1000),2)
)

# Filter by parameter:
selected_data <- dt[Region == params$region]
head(selected_data)
\`\`\`

Running this report with `region = "Europe"` will produce a similar analysis focusing only on Europe’s data.

**To render with different parameters:**
You can run from the R console:  
\`\`\{r, eval=FALSE\}
rmarkdown::render("report.Rmd", params=list(region="Europe"))
\`\`\`

This approach makes it easy to produce many customised reports programmatically.

**Interactive Notebooks:**
- RMarkdown and Quarto support notebook interfaces.  
- When you open an `.Rmd` file in RStudio, you can run code chunks interactively and see outputs immediately, making exploratory analysis more intuitive.  
- Quarto supports Jupyter-like notebook behaviour for multiple languages.  
- You can also embed `shiny` apps or `htmlwidgets` for truly interactive experiences.

**Example with ggplot2 Plot:**
\`\`\{r sales-plot, echo=TRUE, message=FALSE, warning=FALSE\}
if(!requireNamespace("ggplot2", quietly=TRUE)) {
  install.packages("ggplot2")
}
library(ggplot2)

ggplot(selected_data, aes(x=Product, y=Sales)) +
  geom_boxplot(fill="steelblue", alpha=0.7) +
  labs(title=paste("Sales Distribution in", params$region),
       x="Product", y="Sales") +
  theme_minimal()
\`\`\`

This code chunk will produce a boxplot of Sales by Product for the specified region. By changing the parameter `region` in your report’s YAML header or through `rmarkdown::render()`, you instantly get a new plot for a different region—no manual changes needed.

### Quarto vs RMarkdown

**Quarto** builds on the concept of RMarkdown, offering:
- **More Extensive Language Support:** R, Python, Julia, and Observable JS.  
- **Flexible Output Formats:** Quarto can produce scientific articles, books, websites, and blogs more seamlessly.  
- **Built-In Visual Themes:** Enhanced styling and layout options.

If you’re starting fresh, you might consider Quarto as a more modern choice, but RMarkdown remains widely used and integrated into RStudio.

### knitr Under the Hood

**knitr:** The engine that executes code chunks in `.Rmd` files, capturing outputs and inserting them into the final document. It’s highly customisable:
- Control code chunk options (echo, eval, results, warnings).
- Integrate with caching to speed up repeated renders.
- Manage figure sizes, captions, and layouts easily.

**Example of Chunk Options:**
\`\`\{r summary, echo=TRUE, results="markup"\}
summary(selected_data$Sales)
\`\`\`

This displays a summary of `Sales` directly in the output, no copy-paste needed.

---

**Key Takeaways:**
- **Literate Programming:** Combine code, text, and results for reproducible, communicative research documents.
- **RMarkdown/Quarto:** Flexible formats that let you produce static and interactive documents, enhancing collaboration and reproducibility.
- **Parameterised Reports:** Automate repetitive analysis tasks by setting parameters at render time.
- **Interactive Notebooks:** Run code live, see outputs instantly, and refine analysis on the fly.

By using RMarkdown or Quarto (backed by knitr), you create living documents that tell the full story of your data analysis journey. These tools help ensure your work can be validated, reused, and understood by collaborators, reviewers, and future you—a crucial asset in any data science workflow.

[^1]: Knuth, D. E. (1984). Literate Programming. The Computer Journal, 27(2), 97–111.


## Scientific Communication and Reporting

In the practice of data analysis and statistical research, the ultimate goal often extends beyond obtaining results to effectively conveying those results to a variety of audiences. This involves not just the raw numbers and tests, but also a nuanced explanation of their meaning, relevance, and limitations. Effective scientific communication builds bridges between complex quantitative methods and decision-makers, stakeholders, or the general public who rely on these findings to guide actions and policies.

### Writing Effective Statistical Reports

- **Clarity and Structure:**  
  Begin any statistical report with a clear introduction stating the purpose, research questions, and the context of the analysis. Follow a logical flow:
  1. **Introduction:** Problem background, research objectives, and data description.  
  2. **Methodology:** Data sources, assumptions, statistical methods, and modelling approaches.  
  3. **Results:** Key findings presented using figures, tables, and concise text.  
  4. **Discussion:** Interpretation, relevance of findings, comparison with existing literature or known benchmarks.  
  5. **Conclusion:** Main takeaways, implications for practice, policy recommendations, or future research directions.

- **Precision and Accuracy:**  
  Use proper statistical terminology and avoid ambiguous language. For example, instead of saying “there’s a big effect,” quantify the magnitude and uncertainty: “The estimated increase in mean income is £500 (95% CI: £450 to £550).”

- **Contextualisation:**  
  Situate statistical findings within the broader domain. A significant difference in test scores might mean something entirely different depending on the educational environment, sample population, or measurement conditions.  
  If you’re reporting on a public health survey, contextualise improvements in health metrics relative to historical trends or known thresholds from prior studies.

- **Appropriate Level of Detail:**  
  Strike a balance. Include enough technical detail (e.g., sample sizes, model assumptions, convergence checks) for scientific credibility, but use appendices or supplementary materials for highly technical derivations. This keeps the main narrative accessible.

**Demonstration:** Suppose we have a dataset from a public health intervention aimed at reducing smoking prevalence[^1]. After processing data using `data.table::fread()` and applying logistic regression with `glm()`, you’ve found a significant reduction in smoking odds after the intervention.

\`\`\{r, echo=TRUE\}
if(!requireNamespace("data.table", quietly=TRUE)) {
  install.packages("data.table")
}
if(!requireNamespace("ggplot2", quietly=TRUE)) {
  install.packages("ggplot2")
}
library(data.table)
library(ggplot2)

# Hypothetical dataset: Pre- and post-intervention smoking prevalence
# Comment: If no real dataset available, let me know and I will find one.
set.seed(123)
N <- 200
dt <- data.table(
  period = rep(c("Pre", "Post"), each=N),
  smoke = rbinom(2*N, size=1, prob=c(0.3,0.2)[rep(1:2, each=N)])
)

# Simple summary
pre_rate <- mean(dt[period=="Pre"]$smoke)
post_rate <- mean(dt[period=="Post"]$smoke)

pre_rate; post_rate
\`\`\`

In the report, you might write: *“Before the intervention, 30% of participants reported regular smoking, compared to 20% after the intervention, indicating a 10 percentage point reduction.”*

### Visual Communication Principles

- **Simplicity:**  
  A good figure communicates one or two key messages. Use clear axes labels, meaningful titles, and avoid chart junk (unnecessary lines, shading, or 3D effects).

- **Consistency in Colours and Scales:**  
  Use consistent colour schemes throughout the report. For comparisons across groups, assign each group a distinct, easily distinguishable colour. Align scales so that differences are accurately perceived.

- **Highlighting Key Findings:**  
  If one group’s improvement is central to your argument, visually emphasise it. Use annotations, arrows, or subtle colour changes to direct the reader’s attention.

- **In-line Graphics with ggplot2:**  
  R’s `ggplot2` enables quick and elegant plotting. For instance, to visualise smoking prevalence before and after:

\`\`\{r, echo=TRUE\}
ggplot(dt, aes(x=period, y=smoke)) +
  stat_summary(fun=mean, geom="bar", fill="steelblue") +
  stat_summary(fun.data=mean_cl_normal, geom="errorbar", width=0.2) +
  labs(title="Smoking Prevalence Before and After Intervention",
       x="Period", y="Proportion Smoking") +
  theme_minimal()
\`\`\`

This bar chart with error bars shows the change in mean smoking prevalence and conveys uncertainty via confidence intervals.

### Addressing Uncertainty and Limitations

- **Uncertainty Intervals and P-values:**  
  Always present estimates with confidence or credible intervals. This emphasises the probabilistic nature of findings. A point estimate without uncertainty can be misleading, suggesting false precision.

- **Model Assumptions and Sensitivity Analyses:**  
  Mention assumptions (normality, independence, linearity) and how they were checked. If possible, report sensitivity analyses showing how results vary under different assumptions or methods. For instance, if a logistic regression result is sensitive to one outlier, note that and, if appropriate, re-run the model without that outlier to show its effect.

- **Limitations:**  
  Acknowledge what your analysis cannot conclude. For example, a cross-sectional study might show an association but not prove causation. Discuss limitations related to sample size, measurement error, or potential biases (e.g., self-selection bias in a survey).

### Communicating to Non-Technical Audiences

- **Use Plain Language:**  
  Replace jargon: instead of “heteroscedasticity,” say “the variability in responses increased at higher income levels.” Use analogies: “Just as a thermometer might read slightly differently each time you measure, our estimate might vary if we repeated the survey.”

- **Focus on Practical Significance:**  
  Non-technical stakeholders care about the magnitude and implications of your findings. For instance, “Our public health intervention is associated with a 10% absolute reduction in smoking prevalence, meaning that in a population of 1000 people, about 100 fewer individuals are smoking.”

- **Tell a Story:**  
  Begin with a problem: “Smoking is a leading cause of preventable disease.” Then show how data-driven insights help: “This intervention reduced the likelihood of smoking, potentially preventing dozens of chronic illnesses in our community each year.”

- **Visual Aids and Infographics:**  
  Simplify complex plots. Consider using more intuitive plots: proportion bars, icons, or line charts with clear markers. If readers are policy-makers, a simple infographic highlighting the main reduction in smoking prevalence might be more powerful than a detailed regression table.

---

**Key Takeaways:**
- Effective statistical reporting involves a balance of clarity, context, and completeness.
- Visual communication is as important as the numerical results—use effective plots and straightforward designs.
- Always present uncertainty and discuss limitations honestly; this increases trust and credibility.
- Tailor communication style to your audience: technical peers might appreciate details and codes of model checking, while a non-technical audience might benefit more from clear analogies and practical implications.

By mastering the art of scientific communication and reporting, you transform raw statistical output into actionable insights that can influence policy, practice, and understanding across diverse fields.

[^1]: Consider using publicly available datasets, such as those from the WHO or CDC, which provide real-world health survey data. You might simulate data for demonstration, as done here, or fetch real datasets from an online repository.