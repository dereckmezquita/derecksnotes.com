---
letter: 'd'
word: 'decision-tree'
dictionary: 'mathematics'
category: 'machine-learning'
dataSource: 'assistant'
published: true
comments: true
linksTo: ['binary-operation','entropy','information-gain']
linkedFrom: []
output:
  html_document:
    keep_md: true
---



<a id="decision-tree">Decision Tree</a> - A **decision tree** is a model that splits data by features to produce a tree of decisions for classification or regression. Nodes perform tests (e.g., $x_j < c$), and leaves provide outcomes or values.

**Key points**:
- For classification, we measure impurity using [entropy](#entropy) or Gini index, splitting to maximise [information-gain](#information-gain).
- For regression, splits often minimise sum of squared errors in leaves.

**R demonstration** (using `rpart` for a simple tree):


``` r
library(rpart)
library(rpart.plot)
library(data.table)

set.seed(123)
n <- 50
x1 <- runif(n, min=0, max=5)
x2 <- runif(n, min=0, max=5)
y_class <- ifelse(x1 + x2 + rnorm(n, sd=1) > 5, "A","B")

dt_tree <- data.table(x1=x1, x2=x2, y=y_class)
fit_tree <- rpart(y ~ x1 + x2, data=dt_tree, method="class")
rpart.plot(fit_tree)
```

<Figure src="/Users/work/Coding/derecksprojects/derecksnotes.com-playground/derecksnotes.com/client/src/app/dictionaries/mathematics/definitions/mathematics_machine-learning_d_decision-tree_files/figure-html/unnamed-chunk-1-1.png">
	
</Figure>
